{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "#sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import utilidades as myutils\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_group_data(dataset, parameter, range_upper = 1,range_lower = 1):\n",
    "    \n",
    "    q1, q3 = np.percentile(dataset[parameter],[25,75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q3 - range_upper*(1.5 * iqr)  \n",
    "    upper_bound = q3 + range_upper*(1.5 * iqr)  \n",
    "\n",
    "    # Deleting lower bound and upper bound from the dataset LinkTT2\n",
    "    dataset = dataset.loc[(dataset[parameter] >= lower_bound) & \n",
    "                                              (dataset[parameter] <= upper_bound)]\n",
    "    #dataset.interpolate()\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def resultado(df,tecnica,parameter,amostras,metrica,rmse,lag):\n",
    "    \n",
    "    df.loc[len(df)]= [tecnica,parameter,amostras,round(metrica,2),round(rmse,2),lag]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "def previsoes(df,parametro,data_coleta,observado,previsao,lag):\n",
    "    \n",
    "    df.loc[len(df)]= [parametro,data_coleta,observado,previsao,lag]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "#Prepara o conjunto de dados em X e y, considerando a janela de visualização (lags).\n",
    "#cy = coluna que será predita\n",
    "def prepara_dados(dados,lags,cy):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(lags, len(dados)):\n",
    "        X.append(dados[i-lags:i,:])\n",
    "        y.append(dados[i, cy])\n",
    "       \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def pegar_dados_coluna_predita_train_test(trainingd,percent,index_coluna):\n",
    "    data = trainingd.iloc[:,:].values\n",
    "    train = trainingd.iloc[0:int(len(data)*percent),index_coluna:index_coluna+1].values\n",
    "    train_previsao = trainingd.iloc[0:int(len(data)*percent),index_coluna:index_coluna+1].values\n",
    "    test = trainingd.iloc[len(train):,index_coluna:index_coluna+1].values \n",
    "    '''\n",
    "    print('Nº observações:', len(data))\n",
    "    print('treino:',len(train))\n",
    "    print('teste:',len(test))\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return train,train_previsao, test\n",
    "\n",
    "#Normalização dos dados: Normaliza os dados dentro um intervalo (0 a 1).\n",
    "def normalizacao(train,test):\n",
    "    sc = MinMaxScaler()\n",
    "    testd = test\n",
    "    train = sc.fit_transform(train)\n",
    "    test = sc.fit_transform(test)    \n",
    "    return train,test,testd\n",
    "\n",
    "def tranformacao_log(valores_parametro):\n",
    "   \n",
    "    valores_log = []\n",
    "   \n",
    "    for i in range(len(valores_parametro)):\n",
    "        #print(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "        valores_log.append(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "       \n",
    "    return valores_log\n",
    "\n",
    "def cria_dataframe_obsprevisoes(data_coleta,observado,previsao,lags,tecnica):\n",
    "    \n",
    "    dict = {'data_coleta':data_coleta,'observado': observado, 'previsao': previsao, 'lags': lags,'tecnica':tecnica}\n",
    "    \n",
    "    dfobsprev = pd.DataFrame(dict)\n",
    "    \n",
    "    return dfobsprev\n",
    "\n",
    "def ajusta_lista(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def rmse(y_true,y_pred):\n",
    "    #mse = mean_squared_error(y_true, y_pred)\n",
    "    #rmse = math.sqrt(mse)\n",
    "    rmse = mean_squared_error(y_true, y_pred,squared = False)\n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Baseline com dados de teste\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','rmse','lag'])\n",
    "#dfprevisoes = pd.DataFrame(columns=['parametro','data_coleta','observado','previsao','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    DFmerged = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    #print(parameter)\n",
    "     \n",
    "    DFmerged = clean_group_data(DFmerged, 'valor')\n",
    "    \n",
    "    DFmerged['data_coleta'] = pd.to_datetime(DFmerged['data_coleta'])\n",
    "    DFmerged.index = DFmerged['data_coleta']    \n",
    "    DFmerged = DFmerged.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged = DFmerged.loc['1979-01-31':]\n",
    "    \n",
    "    DFmerged = DFmerged.interpolate(method = 'pad')\n",
    "    \n",
    "    dfnovo = DFmerged\n",
    "    dfnovo = dfnovo.reset_index()\n",
    "    \n",
    "    ##Transforma os dados do coliformes em log\n",
    "    if (parameter == 'Coliformes Termotolerantes'):\n",
    "        DFmerged[parameter] = tranformacao_log(DFmerged[parameter])\n",
    "        \n",
    "    ##Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    ##seleciona os dados\n",
    "    \n",
    "    train,train_previsao, test = pegar_dados_coluna_predita_train_test(DFmerged,0.70,0)\n",
    "    #y_test = test\n",
    "    \n",
    "    dfprevisoes = pd.DataFrame()\n",
    "    \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        entradas = DFmerged[len(DFmerged) - len(test):].values\n",
    "        data = dfnovo.iloc[len(DFmerged) - len(test):,0:1].values \n",
    "        data = ajusta_lista(data[lags:])\n",
    "        observado = ajusta_lista(entradas[0:-lags])\n",
    "        previsao  = ajusta_lista(entradas[lags:])\n",
    "        \n",
    "        dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'Baseline')\n",
    "        #dfprevisoes  = dfprevisoes1.round(2)\n",
    "        \n",
    "        dfprevisoes = pd.concat([dfprevisoes, dfprevisoes1])           \n",
    "                                        \n",
    "        df_result = resultado(df_resultado,'Baseline',parameter,len(entradas),\n",
    "                              myutils.mean_absolute_percentage_error(entradas[0:-lags], entradas[lags:]),\n",
    "                              rmse(entradas[0:-lags], entradas[lags:]),lags)\n",
    "        \n",
    "                \n",
    "    dfprevisoes.round(2).to_csv (r'/home/anderson/Downloads/predicaoagua/src/previsoes/baseline/serie_temporal_baseline_'+parameter+'.csv', index = False, header=True)                               \n",
    "    \n",
    "\n",
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/previsoes/baseline/metricas_temporal_baseline.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>46</td>\n",
       "      <td>55.41</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>46</td>\n",
       "      <td>55.37</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>46</td>\n",
       "      <td>66.93</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>46</td>\n",
       "      <td>47.23</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>46</td>\n",
       "      <td>41.82</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>54</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>54</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>54</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>54</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>54</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tecnica                   parametro amostras   mape  rmse lag\n",
       "0    Regressão Linear  Coliformes Termotolerantes       46  55.41  1.72   1\n",
       "1       Random Forest  Coliformes Termotolerantes       46  55.37  1.71   1\n",
       "2                 MLP  Coliformes Termotolerantes       46  66.93  2.89   1\n",
       "3                LSTM  Coliformes Termotolerantes       46  47.23  1.52   1\n",
       "4    Regressão Linear  Coliformes Termotolerantes       46  41.82  1.95   2\n",
       "..                ...                         ...      ...    ...   ...  ..\n",
       "315              LSTM                          pH       54   2.68  0.22   9\n",
       "316  Regressão Linear                          pH       54   3.11  0.24  10\n",
       "317     Random Forest                          pH       54   3.19  0.24  10\n",
       "318               MLP                          pH       54   3.72  0.29  10\n",
       "319              LSTM                          pH       54   2.67  0.22  10\n",
       "\n",
       "[320 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Temporal\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','rmse','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    DFmerged = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    #print(parameter)\n",
    "     \n",
    "    DFmerged = clean_group_data(DFmerged, 'valor')\n",
    "    \n",
    "    DFmerged['data_coleta'] = pd.to_datetime(DFmerged['data_coleta'])\n",
    "    DFmerged.index = DFmerged['data_coleta']    \n",
    "    DFmerged = DFmerged.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged = DFmerged.loc['1979-01-31':]\n",
    "    \n",
    "    DFmerged = DFmerged.interpolate(method = 'pad')\n",
    "    \n",
    "    dfnovo = DFmerged\n",
    "    dfnovo = dfnovo.reset_index()\n",
    "    \n",
    "    ##Transforma os dados do coliformes em log\n",
    "    if (parameter == 'Coliformes Termotolerantes'):\n",
    "        DFmerged[parameter] = tranformacao_log(DFmerged[parameter])\n",
    "    #DFmerged[parameter] = tranformacao_log(DFmerged[parameter])\n",
    "        \n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    #seleciona os dados\n",
    "    \n",
    "    train,train_previsao, test = pegar_dados_coluna_predita_train_test(DFmerged,0.70,0)\n",
    "    y_test = test\n",
    "    \n",
    "    df_previsoes   = pd.DataFrame()\n",
    "    \n",
    "    #normalização dos dados\n",
    "    scaler = MinMaxScaler()\n",
    "    train,test,testd = normalizacao(train,test)\n",
    "            \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        \n",
    "                \n",
    "        #Prepara os dados de treinamento\n",
    "        train_X,train_y = prepara_dados(train, lags,0)  \n",
    "        train_X_lstm = train_X\n",
    "        train_y_lstm = train_y\n",
    "                \n",
    "        #Ajusta a dimensão de train_X \n",
    "        nsamples, nx, ny = train_X.shape\n",
    "        train_X = train_X.reshape((nsamples,nx*ny))\n",
    "    \n",
    "        #Prepara os dados de teste\n",
    "        entradas = DFmerged[len(DFmerged) - len(test) - lags:].values\n",
    "        entradas = scaler.fit_transform(entradas)  \n",
    "    \n",
    "        test_X = []\n",
    "        for i in range(lags, lags+len(test)):        \n",
    "            test_X.append(entradas[i-lags:i, 0:1])\n",
    "        test_X = np.array(test_X)\n",
    "        \n",
    "        test_X_lstm = test_X\n",
    "                \n",
    "        #Ajusta a dimensão de test_X e train_X\n",
    "        nsamples, nx, ny = test_X.shape\n",
    "        test_X = test_X.reshape((nsamples,nx*ny))\n",
    "                                                        \n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        model.fit(train_X,train_y)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X).reshape(-1, 1) \n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        \n",
    "        #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica RL.\n",
    "        data = dfnovo.iloc[len(train):,0:1].values \n",
    "        data = ajusta_lista(data)\n",
    "        observado = ajusta_lista(y_test)\n",
    "        previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "        dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'Regressão Linear')\n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "        \n",
    "        #Grava os resultados das métricas MAPE e RMSE por cada lag e técnica.               \n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(y_test),\n",
    "                              myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes),rmse(y_test[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        #Random Forest\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        model.fit(train_X,train_y)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X).reshape(-1, 1)\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        \n",
    "        #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica RF.\n",
    "        data = dfnovo.iloc[len(train):,0:1].values \n",
    "        data = ajusta_lista(data)\n",
    "        observado = ajusta_lista(y_test)\n",
    "        previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "        dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'Random Forest')\n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "        \n",
    "        df_result = resultado(df_resultado,'Random Forest',parameter,len(y_test),\n",
    "                              myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes),rmse(y_test[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #MLP\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = 50, activation = 'relu', input_dim = train_X.shape[1]))\n",
    "        model.add(Dense(units = 50, activation = 'relu'))\n",
    "        model.add(Dense(units = 1, activation = 'relu'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X,train_y, validation_data = (train_X,train_y),  batch_size = 4, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        media_rmse      = []\n",
    "        mape = 0        \n",
    "                \n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            \n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes)) \n",
    "            \n",
    "            media_rmse.append(rmse(y_test,previsoes))\n",
    "            \n",
    "            #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica MLP.\n",
    "            #A ideia é encontrar o no menor MAPE, logo representa a serie temporal da predição de melhor desempenho.\n",
    "            if (r == 0):\n",
    "                mape = myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes) \n",
    "                data = dfnovo.iloc[len(train):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'MLP')\n",
    "                #dfprevisoes  = dfprevisoes1\n",
    "                \n",
    "            elif (mape > myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes)):\n",
    "                \n",
    "                mape = myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes)\n",
    "                \n",
    "                data = dfnovo.iloc[len(train):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'MLP')\n",
    "                          \n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "\n",
    "        df_result = resultado(df_resultado,'MLP',parameter,len(y_test),np.mean(media_previsoes),np.mean(media_rmse),lags)\n",
    "\n",
    "    \n",
    "        #LSTM\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 50, input_shape = (train_X_lstm.shape[1], 1)))\n",
    "        model.add(Dense(50, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation = 'relu'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X_lstm,train_y_lstm,validation_data = (train_X_lstm,train_y_lstm), batch_size = 4, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        media_rmse      = []\n",
    "        mape = 0 \n",
    "       \n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X_lstm)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            \n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes)) \n",
    "            \n",
    "            media_rmse.append(rmse(y_test,previsoes))\n",
    "            \n",
    "            #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica LSTM.\n",
    "            #A ideia é encontrar o no menor MAPE, logo representa a serie temporal da predição de melhor desempenho.\n",
    "            if (r == 0):\n",
    "                mape = myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes) \n",
    "                data = dfnovo.iloc[len(train):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'LSTM')\n",
    "                                \n",
    "            elif (mape > myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes)):\n",
    "                \n",
    "                mape = myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes)\n",
    "                \n",
    "                data = dfnovo.iloc[len(train):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'LSTM')\n",
    "            \n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "\n",
    "        df_result = resultado(df_resultado,'LSTM',parameter,len(y_test),np.mean(media_previsoes),np.mean(media_rmse),lags)\n",
    "            \n",
    "    df_previsoes.round(2).to_csv (r'/home/anderson/Downloads/predicaoagua/src/previsoes/baseline/predicao_serie_temporal_'+parameter+'.csv', index = False, header=True)                               \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/previsoes/baseline/metricas_temporal_tecnicas.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espaço-temporal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.435556e+10</td>\n",
       "      <td>7.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>2.147328e+10</td>\n",
       "      <td>7.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>9.744000e+01</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.775113e+10</td>\n",
       "      <td>6.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.550515e+10</td>\n",
       "      <td>6.98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>1.920000e+00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>2.060000e+00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>2.090000e+00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>2.360000e+00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>1.970000e+00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tecnica                   parametro amostras          mape  \\\n",
       "0    Regressão Linear  Coliformes Termotolerantes      127  1.435556e+10   \n",
       "1       Random Forest  Coliformes Termotolerantes      127  2.147328e+10   \n",
       "2                 MLP  Coliformes Termotolerantes      127  9.744000e+01   \n",
       "3                LSTM  Coliformes Termotolerantes      127  1.775113e+10   \n",
       "4    Regressão Linear  Coliformes Termotolerantes      127  1.550515e+10   \n",
       "..                ...                         ...      ...           ...   \n",
       "315              LSTM                          pH      159  1.920000e+00   \n",
       "316  Regressão Linear                          pH      159  2.060000e+00   \n",
       "317     Random Forest                          pH      159  2.090000e+00   \n",
       "318               MLP                          pH      159  2.360000e+00   \n",
       "319              LSTM                          pH      159  1.970000e+00   \n",
       "\n",
       "      rmse lag  \n",
       "0     7.35   1  \n",
       "1     7.56   1  \n",
       "2    12.80   1  \n",
       "3     6.26   1  \n",
       "4     6.98   2  \n",
       "..     ...  ..  \n",
       "315   0.17   9  \n",
       "316   0.18  10  \n",
       "317   0.18  10  \n",
       "318   0.20  10  \n",
       "319   0.17  10  \n",
       "\n",
       "[320 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espaço-temporal\n",
    "print('predição espaço-temporal')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','rmse','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    #DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      #(DFmerge['parametro'] == parameter)]\n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET04150') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #if (len(DFmerged1) > len(DFmerged2)):\n",
    "        #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #else:\n",
    "        #DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    \n",
    "    DFmerged1 = DFmerged1.interpolate(method = 'pad')\n",
    "    DFmerged2 = DFmerged2.interpolate(method = 'pad')\n",
    "    \n",
    "    ##Transforma os dados do coliformes em log\n",
    "    if (parameter == 'Coliformes Termotolerantes'):\n",
    "        DFmerged1[parameter] = tranformacao_log(DFmerged1[parameter])\n",
    "        DFmerged2[parameter] = tranformacao_log(DFmerged2[parameter])\n",
    "    \n",
    "    DFmerged3 = DFmerged1.merge(DFmerged2, how='inner', on = 'data_coleta')\n",
    "    \n",
    "    dfnovo = DFmerged3\n",
    "    dfnovo = dfnovo.reset_index()\n",
    "        \n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    #Dividindo dataframe\n",
    "    df2050 = DFmerged3.iloc[:,0:1]\n",
    "    df2090 = DFmerged3.iloc[:,1:2]\n",
    "        \n",
    "    #seleciona os dados\n",
    "\n",
    "    train1,train_previsao1, test1 = pegar_dados_coluna_predita_train_test(df2050,0.70,0)\n",
    "    y_test1 = test1\n",
    "    \n",
    "    train2,train_previsao2, test2 = pegar_dados_coluna_predita_train_test(df2090,0.70,0)\n",
    "    y_test2 = test2\n",
    "    \n",
    "    df_previsoes   = pd.DataFrame()\n",
    "    \n",
    "    #normalização dos dados\n",
    "    scaler = MinMaxScaler()\n",
    "    train1,test1,testd1 = normalizacao(train1,test1)\n",
    "    train2,test2,testd2 = normalizacao(train2,test2)\n",
    "    \n",
    "    #print('y_test2:',y_test2)\n",
    "        \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        \n",
    "                \n",
    "        #Prepara os dados de treinamento\n",
    "        train_X1,train_y1 = prepara_dados(train1, lags,0)  \n",
    "        train_X_lstm1 = train_X1\n",
    "        train_y_lstm1 = train_y1\n",
    "        \n",
    "        train_X2,train_y2 = prepara_dados(train2, lags,0)  \n",
    "        train_X_lstm2 = train_X2\n",
    "        train_y_lstm2 = train_y2\n",
    "                \n",
    "        #Ajusta a dimensão de train_X \n",
    "        nsamples, nx, ny = train_X1.shape\n",
    "        train_X1 = train_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = train_X2.shape\n",
    "        train_X2 = train_X2.reshape((nsamples,nx*ny))\n",
    "    \n",
    "        #Prepara os dados de teste\n",
    "        entradas1 = df2050[len(df2050) - len(test1) - lags:].values\n",
    "        entradas1 = scaler.fit_transform(entradas1)  \n",
    "    \n",
    "        test_X1 = []\n",
    "        for i in range(lags, lags+len(test1)):        \n",
    "            test_X1.append(entradas1[i-lags:i, 0:1])\n",
    "        test_X1 = np.array(test_X1)\n",
    "        \n",
    "        test_X_lstm1 = test_X1\n",
    "        \n",
    "        entradas2 = df2090[len(df2090) - len(test2) - lags:].values\n",
    "        entradas2 = scaler.fit_transform(entradas2)  \n",
    "    \n",
    "        test_X2 = []\n",
    "        for i in range(lags, lags+len(test2)):        \n",
    "            test_X2.append(entradas2[i-lags:i, 0:1])\n",
    "        test_X2 = np.array(test_X2)\n",
    "        \n",
    "        test_X_lstm2 = test_X2\n",
    "                \n",
    "        #Ajusta a dimensão de test_X e train_X\n",
    "        nsamples, nx, ny = test_X1.shape\n",
    "        test_X1 = test_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = test_X2.shape\n",
    "        test_X2 = test_X2.reshape((nsamples,nx*ny))\n",
    "                                                \n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        model.fit(train_X1,train_y1)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X2).reshape(-1, 1) \n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        #print('previsoes',len(previsoes))\n",
    "        #print('testd2',len(testd2))\n",
    "        #print('y_test2',y_test2)\n",
    "        #y_test2[:len(previsoes)]\n",
    "        \n",
    "        #Organiza para salvar no dataframe as series espaço-temporais observado e predito por cada lag e técnica RL.\n",
    "        data = dfnovo.iloc[len(train1):,0:1].values \n",
    "        data = ajusta_lista(data)\n",
    "        #print('y_test2',y_test2)\n",
    "        observado = ajusta_lista(y_test2)\n",
    "        previsao  = ajusta_lista(previsoes)\n",
    "                \n",
    "        dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'Regressão Linear')\n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "               \n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged3),\n",
    "                              myutils.mean_absolute_percentage_error(y_test2, previsoes),rmse(y_test2, previsoes),lags)\n",
    "        \n",
    "        \n",
    "        #Random Forest\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        model.fit(train_X1,train_y1)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X2).reshape(-1, 1)\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        \n",
    "        #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica RF.\n",
    "        data = dfnovo.iloc[len(train1):,0:1].values \n",
    "        data = ajusta_lista(data)\n",
    "        observado = ajusta_lista(y_test2)\n",
    "        previsao  = ajusta_lista(previsoes)\n",
    "                \n",
    "        dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'Random Forest')\n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "\n",
    "        df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged3),\n",
    "                              myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes),rmse(y_test2[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        #MLP\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = 50, activation = 'relu', input_dim = train_X1.shape[1]))\n",
    "        model.add(Dense(units = 50, activation = 'relu'))\n",
    "        model.add(Dense(units = 1, activation = 'relu'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X1,train_y1, validation_data = (train_X2,train_y2),  batch_size = 4, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        media_rmse      = []\n",
    "        mape = 0        \n",
    "        \n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X2)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes)) \n",
    "            \n",
    "            media_rmse.append(rmse(y_test2,previsoes))\n",
    "            \n",
    "            #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica MLP.\n",
    "            #A ideia é encontrar o no menor MAPE, logo representa a serie temporal da predição de melhor desempenho.\n",
    "            if (r == 0):\n",
    "                mape = myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes) \n",
    "                data = dfnovo.iloc[len(train1):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test2)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'MLP')\n",
    "                #dfprevisoes  = dfprevisoes1\n",
    "                \n",
    "            elif (mape > myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes)):\n",
    "                \n",
    "                mape = myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes)\n",
    "                \n",
    "                data = dfnovo.iloc[len(train1):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test2)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'MLP')\n",
    "                          \n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])  \n",
    "        \n",
    "        df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged3),np.mean(media_previsoes),np.mean(media_rmse),lags)\n",
    "\n",
    "        \n",
    "        #LSTM\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 50, input_shape = (train_X_lstm1.shape[1], 1)))\n",
    "        model.add(Dense(50, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation = 'relu'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X_lstm1,train_y_lstm1,validation_data = (train_X_lstm2,train_y_lstm2), batch_size = 4, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        media_rmse      = []\n",
    "        mape = 0 \n",
    "        \n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X_lstm2)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            \n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes)) \n",
    "            \n",
    "            media_rmse.append(rmse(y_test2,previsoes))\n",
    "            \n",
    "            #Organiza para salvar no dataframe as series temporais observado e predito por cada lag e técnica LSTM.\n",
    "            #A ideia é encontrar o no menor MAPE, logo representa a serie temporal da predição de melhor desempenho.\n",
    "            if (r == 0):\n",
    "                mape = myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes) \n",
    "                data = dfnovo.iloc[len(train1):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test2)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'LSTM')\n",
    "                                \n",
    "            elif (mape > myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes)):\n",
    "                \n",
    "                mape = myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes)\n",
    "                \n",
    "                data = dfnovo.iloc[len(train1):,0:1].values \n",
    "                data = ajusta_lista(data)\n",
    "                observado = ajusta_lista(y_test2)\n",
    "                previsao  = ajusta_lista(previsoes)\n",
    "        \n",
    "                dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'LSTM')\n",
    "            \n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "        \n",
    "        df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged3),np.mean(media_previsoes),np.mean(media_rmse),lags)\n",
    "        \n",
    "    df_previsoes.round(2).to_csv (r'/home/anderson/Downloads/predicaoagua/src/previsoes/baseline/predicao_serie_espaco_temporal_'+parameter+'.csv', index = False, header=True)                                  \n",
    "    \n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.round(2).to_csv (r'/home/anderson/Downloads/predicaoagua/src/previsoes/baseline/metricas_espaco_temporal_tecnicas.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espacial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>28.03</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>26.17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>58.01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>28.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>204</td>\n",
       "      <td>17.57</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>204</td>\n",
       "      <td>19.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>204</td>\n",
       "      <td>30.88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>204</td>\n",
       "      <td>17.47</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>189</td>\n",
       "      <td>34.37</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>189</td>\n",
       "      <td>33.86</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>189</td>\n",
       "      <td>58.59</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>189</td>\n",
       "      <td>36.43</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>14.88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>15.65</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>63.24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>15.54</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>205</td>\n",
       "      <td>1.53</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>205</td>\n",
       "      <td>1.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>205</td>\n",
       "      <td>28.27</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>205</td>\n",
       "      <td>2.52</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>5.42</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>3.13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>36.91</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>36.91</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>1.74</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>1.83</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>8.45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>1.71</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.27</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tecnica                   parametro amostras   mape lag\n",
       "0   Regressão Linear  Coliformes Termotolerantes      151  28.03    \n",
       "1      Random Forest  Coliformes Termotolerantes      151  26.17    \n",
       "2                MLP  Coliformes Termotolerantes      151  58.01    \n",
       "3               LSTM  Coliformes Termotolerantes      151  28.00    \n",
       "4   Regressão Linear         Oxigênio Dissolvido      204  17.57    \n",
       "5      Random Forest         Oxigênio Dissolvido      204  19.25    \n",
       "6                MLP         Oxigênio Dissolvido      204  30.88    \n",
       "7               LSTM         Oxigênio Dissolvido      204  17.47    \n",
       "8   Regressão Linear                    Turbidez      189  34.37    \n",
       "9      Random Forest                    Turbidez      189  33.86    \n",
       "10               MLP                    Turbidez      189  58.59    \n",
       "11              LSTM                    Turbidez      189  36.43    \n",
       "12  Regressão Linear               Fósforo Total      192  14.88    \n",
       "13     Random Forest               Fósforo Total      192  15.65    \n",
       "14               MLP               Fósforo Total      192  63.24    \n",
       "15              LSTM               Fósforo Total      192  15.54    \n",
       "16  Regressão Linear                Sólido Total      205   1.53    \n",
       "17     Random Forest                Sólido Total      205   1.25    \n",
       "18               MLP                Sólido Total      205  28.27    \n",
       "19              LSTM                Sólido Total      205   2.52    \n",
       "20  Regressão Linear                 DBO (5, 20)      161   5.42    \n",
       "21     Random Forest                 DBO (5, 20)      161   3.13    \n",
       "22               MLP                 DBO (5, 20)      161  36.91    \n",
       "23              LSTM                 DBO (5, 20)      161  36.91    \n",
       "24  Regressão Linear         Temperatura da Água      195   1.74    \n",
       "25     Random Forest         Temperatura da Água      195   1.83    \n",
       "26               MLP         Temperatura da Água      195   8.45    \n",
       "27              LSTM         Temperatura da Água      195   1.71    \n",
       "28  Regressão Linear                          pH      179   1.11    \n",
       "29     Random Forest                          pH      179   1.27    \n",
       "30               MLP                          pH      179   1.09    \n",
       "31              LSTM                          pH      179   1.08    "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espacial\n",
    "print('predição espacial')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #if (len(DFmerged1) > len(DFmerged2)):\n",
    "        #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #else:\n",
    "        #DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    DFmerged1 = DFmerged1.interpolate(method = 'pad')\n",
    "    DFmerged2 = DFmerged2.interpolate(method = 'pad')\n",
    "    \n",
    "    DFmerged1[parameter] = tranformacao_log(DFmerged1[parameter])\n",
    "    DFmerged2[parameter] = tranformacao_log(DFmerged2[parameter])\n",
    "    \n",
    "    DFmerged3 = DFmerged1.merge(DFmerged2, how='inner', on = 'data_coleta')\n",
    "    \n",
    "    #dfnovo = DFmerged3\n",
    "    #dfnovo = dfnovo.reset_index()\n",
    "            \n",
    "    #Dividindo dataframe\n",
    "    df2050 = DFmerged3.iloc[:,0:1]\n",
    "    df2090 = DFmerged3.iloc[:,1:2]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    #DFmerged = scaler.fit_transform(np.log(DFmerged + 0.0000001))\n",
    "#     DFmerged = scaler.fit_transform()\n",
    "\n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "        \n",
    "    X  = df2050[:]\n",
    "    y  = df2090[:]\n",
    "\n",
    "\n",
    "    dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "    dataset.columns = ['X','y']\n",
    "    dataset.dropna(inplace=True)\n",
    "\n",
    "    #train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "    #train_y = scaler.fit_transform(np.log(np.array(dataset['y']).reshape(len(dataset), 1) + 0.000000001))\n",
    "    \n",
    "    train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "    train_y = scaler.fit_transform(np.array(dataset['y']).reshape(len(dataset), 1))\n",
    "        \n",
    "    #tamanho_treino = int(len(train_X)*0.7)\n",
    "    tamanho_teste  = int(len(train_y)*0.3)\n",
    "\n",
    "    #Desnormalização train_y(teste)\n",
    "    y_teste = scaler.inverse_transform(train_y[-tamanho_teste:])\n",
    "\n",
    "    #Regressão Linear\n",
    "    model = LinearRegression(normalize=False)\n",
    "\n",
    "    #model.fit(train_X[:-40],train_y[:-40])\n",
    "    model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "    score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "    #Dados de teste\n",
    "    #previsoes = model.predict(train_X[-40:])\n",
    "    previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "    previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "    #df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),myutils.mean_absolute_percentage_error(train_y[-40:], previsoes))\n",
    "    df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),'')\n",
    "        \n",
    "        \n",
    "    #print(parameter, len(DFmerged),'MAPE',str(myutils.mean_absolute_percentage_error(train_y[-40:], previsoes)))\n",
    "\n",
    "    #Random Forest\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "    score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "    #Dados de teste\n",
    "    previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "    previsoes = scaler.inverse_transform(previsoes.reshape(-1, 1))\n",
    "\n",
    "    df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),'')\n",
    "\n",
    "    #MLP\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, activation = 'relu', input_dim = train_X[:-tamanho_teste].shape[1]))\n",
    "    model.add(Dense(units = 21, activation = 'relu'))\n",
    "    model.add(Dense(units = 1, activation = 'relu'))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste], validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]),  batch_size = 4, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "    #Dados de teste\n",
    "    media_previsoes = []\n",
    "    for r in range(0,6):\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))  \n",
    "\n",
    "    df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged1),np.mean(media_previsoes),'')\n",
    "\n",
    "\n",
    "    #LSTM\n",
    "\n",
    "    train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "    train_y = np.reshape(train_y, (train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 10, input_shape = (train_X[:-tamanho_teste].shape[1], 1)))\n",
    "    model.add(Dense(21, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'relu'))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste],validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]), batch_size = 4, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "    #Dados de teste\n",
    "    media_previsoes = []\n",
    "    for r in range(0,6):\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))\n",
    "\n",
    "    df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged1),np.mean(media_previsoes),'')\n",
    "\n",
    "         \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/espacial_pad_limpo_relu.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1979-01-31T00:00:00.000000000', '1979-02-28T00:00:00.000000000',\n",
       "       '1979-03-31T00:00:00.000000000', '1980-01-31T00:00:00.000000000',\n",
       "       '1980-02-29T00:00:00.000000000', '1980-04-30T00:00:00.000000000',\n",
       "       '1980-06-30T00:00:00.000000000', '1980-08-31T00:00:00.000000000',\n",
       "       '1981-01-31T00:00:00.000000000', '1981-03-31T00:00:00.000000000',\n",
       "       '1981-04-30T00:00:00.000000000', '1981-05-31T00:00:00.000000000',\n",
       "       '1982-01-31T00:00:00.000000000', '1982-03-31T00:00:00.000000000',\n",
       "       '1982-04-30T00:00:00.000000000', '1982-05-31T00:00:00.000000000',\n",
       "       '1982-06-30T00:00:00.000000000', '1983-01-31T00:00:00.000000000',\n",
       "       '1983-03-31T00:00:00.000000000', '1983-04-30T00:00:00.000000000',\n",
       "       '1983-12-31T00:00:00.000000000', '1984-01-31T00:00:00.000000000',\n",
       "       '1984-02-29T00:00:00.000000000', '1984-04-30T00:00:00.000000000',\n",
       "       '1984-05-31T00:00:00.000000000', '1984-08-31T00:00:00.000000000',\n",
       "       '1985-01-31T00:00:00.000000000', '1985-02-28T00:00:00.000000000',\n",
       "       '1985-03-31T00:00:00.000000000', '1985-05-31T00:00:00.000000000',\n",
       "       '1986-01-31T00:00:00.000000000', '1986-03-31T00:00:00.000000000',\n",
       "       '1986-07-31T00:00:00.000000000', '1987-01-31T00:00:00.000000000',\n",
       "       '1987-04-30T00:00:00.000000000', '1987-05-31T00:00:00.000000000',\n",
       "       '1988-03-31T00:00:00.000000000', '1988-06-30T00:00:00.000000000',\n",
       "       '1989-01-31T00:00:00.000000000', '1989-07-31T00:00:00.000000000',\n",
       "       '1989-08-31T00:00:00.000000000', '1989-10-31T00:00:00.000000000',\n",
       "       '1990-04-30T00:00:00.000000000', '1990-07-31T00:00:00.000000000',\n",
       "       '1990-08-31T00:00:00.000000000', '1990-11-30T00:00:00.000000000',\n",
       "       '1990-12-31T00:00:00.000000000', '1991-08-31T00:00:00.000000000',\n",
       "       '1991-09-30T00:00:00.000000000', '1991-11-30T00:00:00.000000000',\n",
       "       '1992-03-31T00:00:00.000000000', '1992-08-31T00:00:00.000000000',\n",
       "       '1992-09-30T00:00:00.000000000', '1992-11-30T00:00:00.000000000',\n",
       "       '1993-01-31T00:00:00.000000000', '1993-03-31T00:00:00.000000000',\n",
       "       '1993-05-31T00:00:00.000000000', '1993-08-31T00:00:00.000000000',\n",
       "       '1993-09-30T00:00:00.000000000', '1994-05-31T00:00:00.000000000',\n",
       "       '1994-07-31T00:00:00.000000000', '1994-09-30T00:00:00.000000000',\n",
       "       '1994-10-31T00:00:00.000000000', '1994-12-31T00:00:00.000000000',\n",
       "       '1995-03-31T00:00:00.000000000', '1995-04-30T00:00:00.000000000',\n",
       "       '1995-05-31T00:00:00.000000000', '1995-07-31T00:00:00.000000000',\n",
       "       '1995-11-30T00:00:00.000000000', '1996-01-31T00:00:00.000000000',\n",
       "       '1996-03-31T00:00:00.000000000', '1996-05-31T00:00:00.000000000',\n",
       "       '1996-07-31T00:00:00.000000000', '1996-09-30T00:00:00.000000000',\n",
       "       '1997-01-31T00:00:00.000000000', '1998-05-31T00:00:00.000000000',\n",
       "       '1998-07-31T00:00:00.000000000', '1998-09-30T00:00:00.000000000',\n",
       "       '1998-11-30T00:00:00.000000000', '1999-01-31T00:00:00.000000000',\n",
       "       '1999-05-31T00:00:00.000000000', '1999-09-30T00:00:00.000000000',\n",
       "       '2000-01-31T00:00:00.000000000', '2000-03-31T00:00:00.000000000',\n",
       "       '2000-07-31T00:00:00.000000000', '2000-09-30T00:00:00.000000000',\n",
       "       '2000-11-30T00:00:00.000000000', '2001-03-31T00:00:00.000000000',\n",
       "       '2001-05-31T00:00:00.000000000', '2001-07-31T00:00:00.000000000',\n",
       "       '2001-09-30T00:00:00.000000000', '2001-11-30T00:00:00.000000000',\n",
       "       '2002-01-31T00:00:00.000000000', '2002-03-31T00:00:00.000000000',\n",
       "       '2002-05-31T00:00:00.000000000', '2002-09-30T00:00:00.000000000',\n",
       "       '2002-11-30T00:00:00.000000000', '2003-01-31T00:00:00.000000000',\n",
       "       '2003-03-31T00:00:00.000000000', '2003-04-30T00:00:00.000000000',\n",
       "       '2003-05-31T00:00:00.000000000', '2003-09-30T00:00:00.000000000',\n",
       "       '2003-10-31T00:00:00.000000000', '2004-01-31T00:00:00.000000000',\n",
       "       '2004-03-31T00:00:00.000000000', '2004-05-31T00:00:00.000000000',\n",
       "       '2004-07-31T00:00:00.000000000', '2004-09-30T00:00:00.000000000',\n",
       "       '2004-10-31T00:00:00.000000000', '2005-01-31T00:00:00.000000000',\n",
       "       '2005-03-31T00:00:00.000000000', '2005-07-31T00:00:00.000000000',\n",
       "       '2005-09-30T00:00:00.000000000', '2005-11-30T00:00:00.000000000',\n",
       "       '2005-12-31T00:00:00.000000000', '2006-07-31T00:00:00.000000000',\n",
       "       '2006-08-31T00:00:00.000000000', '2006-10-31T00:00:00.000000000',\n",
       "       '2006-11-30T00:00:00.000000000', '2006-12-31T00:00:00.000000000',\n",
       "       '2007-07-31T00:00:00.000000000', '2007-08-31T00:00:00.000000000',\n",
       "       '2007-09-30T00:00:00.000000000', '2007-11-30T00:00:00.000000000',\n",
       "       '2008-03-31T00:00:00.000000000', '2008-04-30T00:00:00.000000000',\n",
       "       '2008-07-31T00:00:00.000000000', '2008-08-31T00:00:00.000000000',\n",
       "       '2008-11-30T00:00:00.000000000', '2009-07-31T00:00:00.000000000',\n",
       "       '2009-08-31T00:00:00.000000000', '2009-09-30T00:00:00.000000000',\n",
       "       '2009-10-31T00:00:00.000000000', '2009-11-30T00:00:00.000000000',\n",
       "       '2010-03-31T00:00:00.000000000', '2010-05-31T00:00:00.000000000',\n",
       "       '2010-07-31T00:00:00.000000000', '2010-09-30T00:00:00.000000000',\n",
       "       '2010-11-30T00:00:00.000000000', '2011-03-31T00:00:00.000000000',\n",
       "       '2011-05-31T00:00:00.000000000', '2011-06-30T00:00:00.000000000',\n",
       "       '2011-07-31T00:00:00.000000000', '2011-08-31T00:00:00.000000000',\n",
       "       '2011-11-30T00:00:00.000000000', '2012-01-31T00:00:00.000000000',\n",
       "       '2012-05-31T00:00:00.000000000', '2012-07-31T00:00:00.000000000',\n",
       "       '2012-09-30T00:00:00.000000000', '2012-11-30T00:00:00.000000000',\n",
       "       '2013-04-30T00:00:00.000000000', '2013-05-31T00:00:00.000000000',\n",
       "       '2013-06-30T00:00:00.000000000', '2013-09-30T00:00:00.000000000',\n",
       "       '2013-10-31T00:00:00.000000000', '2013-11-30T00:00:00.000000000',\n",
       "       '2014-01-31T00:00:00.000000000', '2014-05-31T00:00:00.000000000',\n",
       "       '2014-07-31T00:00:00.000000000', '2014-09-30T00:00:00.000000000',\n",
       "       '2014-11-30T00:00:00.000000000', '2014-12-31T00:00:00.000000000',\n",
       "       '2015-01-31T00:00:00.000000000', '2015-05-31T00:00:00.000000000',\n",
       "       '2015-07-31T00:00:00.000000000', '2015-09-30T00:00:00.000000000',\n",
       "       '2015-11-30T00:00:00.000000000', '2016-07-31T00:00:00.000000000',\n",
       "       '2016-09-30T00:00:00.000000000', '2016-10-31T00:00:00.000000000',\n",
       "       '2016-11-30T00:00:00.000000000', '2017-09-30T00:00:00.000000000',\n",
       "       '2017-11-30T00:00:00.000000000', '2018-05-31T00:00:00.000000000',\n",
       "       '2018-08-31T00:00:00.000000000', '2018-09-30T00:00:00.000000000',\n",
       "       '2018-10-31T00:00:00.000000000', '2018-11-30T00:00:00.000000000',\n",
       "       '2019-09-30T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tranformacao_log(valores_parametro):\n",
    "   \n",
    "    valores_log = []\n",
    "   \n",
    "    for i in range(len(valores_parametro)):\n",
    "        #print(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "        valores_log.append(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "       \n",
    "    return valores_log\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    DFmerged = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "\n",
    "    \n",
    "\n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged = DFmerged[DFmerged['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged = clean_group_data(DFmerged, 'valor')\n",
    "       \n",
    "    DFmerged['data_coleta'] = pd.to_datetime(DFmerged['data_coleta'])\n",
    "    DFmerged.index = DFmerged['data_coleta']    \n",
    "    DFmerged = DFmerged.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged = DFmerged.loc['1979-01-31':]\n",
    "    \n",
    "    DFmerged.interpolate(method = 'pad')\n",
    "    \n",
    "    dfnovo = DFmerged\n",
    "    dfnovo = dfnovo.reset_index()\n",
    "    \n",
    "    dfnovo = dfnovo.iloc[]\n",
    "    data = dfnovo['data_coleta'].values\n",
    "    \n",
    "      \n",
    "    scaler = MinMaxScaler()\n",
    "    DFmerged = tranformacao_log(DFmerged[parameter])\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espaço-temporal\n"
     ]
    }
   ],
   "source": [
    "#predição espaço-temporal\n",
    "print('predição espaço-temporal')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #if (len(DFmerged1) > len(DFmerged2)):\n",
    "        #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #else:\n",
    "        #DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    \n",
    "    DFmerged1 = DFmerged1.interpolate(method = 'pad')\n",
    "    DFmerged2 = DFmerged2.interpolate(method = 'pad')\n",
    "        \n",
    "    DFmerged1[parameter] = tranformacao_log(DFmerged1[parameter])\n",
    "    DFmerged2[parameter] = tranformacao_log(DFmerged2[parameter])\n",
    "    \n",
    "    DFmerged3 = DFmerged1.merge(DFmerged2, how='inner', on = 'data_coleta')\n",
    "    \n",
    "    dfnovo = DFmerged3\n",
    "    dfnovo = dfnovo.reset_index()\n",
    "        \n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    #Dividindo dataframe\n",
    "    df2050 = DFmerged3.iloc[:,0:1]\n",
    "    df2090 = DFmerged3.iloc[:,1:2]\n",
    "                            \n",
    "    train1,train_previsao1, test1 = pegar_dados_coluna_predita_train_test(df2050,0.70,0)\n",
    "    y_test1 = test1\n",
    "    \n",
    "  \n",
    "    train2,train_previsao2, test2 = pegar_dados_coluna_predita_train_test(df2090,0.70,0)\n",
    "    y_test2 = test2\n",
    "    \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        #normalização dos dados\n",
    "        scaler = MinMaxScaler()\n",
    "        train1,test1,testd1 = normalizacao(train1,test1)\n",
    "        train2,test2,testd2 = normalizacao(train2,test2)\n",
    "                \n",
    "        #Prepara os dados de treinamento\n",
    "        train_X1,train_y1 = prepara_dados(train1, lags,0)  \n",
    "        train_X_lstm1 = train_X1\n",
    "        train_y_lstm1 = train_y1\n",
    "        \n",
    "        train_X2,train_y2 = prepara_dados(train2, lags,0)  \n",
    "        train_X_lstm2 = train_X2\n",
    "        train_y_lstm2 = train_y2\n",
    "                \n",
    "        #Ajusta a dimensão de train_X \n",
    "        nsamples, nx, ny = train_X1.shape\n",
    "        train_X1 = train_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = train_X2.shape\n",
    "        train_X2 = train_X2.reshape((nsamples,nx*ny))\n",
    "    \n",
    "        #Prepara os dados de teste\n",
    "        entradas1 = df2050[len(df2050) - len(test1) - lags:].values\n",
    "        entradas1 = scaler.fit_transform(entradas1)  \n",
    "    \n",
    "        test_X1 = []\n",
    "        for i in range(lags, lags+len(test1)):        \n",
    "            test_X1.append(entradas1[i-lags:i, 0:1])\n",
    "        test_X1 = np.array(test_X1)\n",
    "        \n",
    "        test_X_lstm1 = test_X1\n",
    "        \n",
    "        entradas2 = df2090[len(df2090) - len(test2) - lags:].values\n",
    "        entradas2 = scaler.fit_transform(entradas2)  \n",
    "    \n",
    "        test_X2 = []\n",
    "        for i in range(lags, lags+len(test2)):        \n",
    "            test_X2.append(entradas2[i-lags:i, 0:1])\n",
    "        test_X2 = np.array(test_X2)\n",
    "        \n",
    "        \n",
    "        test_X_lstm2 = test_X2\n",
    "                \n",
    "        #Ajusta a dimensão de test_X e train_X\n",
    "        nsamples, nx, ny = test_X1.shape\n",
    "        test_X1 = test_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = test_X2.shape\n",
    "        test_X2 = test_X2.reshape((nsamples,nx*ny))\n",
    "        \n",
    "              \n",
    "        '''\n",
    "        dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "        dataset.columns = ['X','y']\n",
    "        dataset.dropna(inplace=True)\n",
    "        '''\n",
    "                        \n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        model.fit(train_X1,train_y1)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X2).reshape(-1, 1) \n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>parametro</th>\n",
       "      <th>pH_x</th>\n",
       "      <th>pH_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_coleta</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-01-31</th>\n",
       "      <td>1.824549</td>\n",
       "      <td>1.894617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-02-28</th>\n",
       "      <td>1.813738</td>\n",
       "      <td>1.851076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.856298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-31</th>\n",
       "      <td>1.890850</td>\n",
       "      <td>1.887070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-29</th>\n",
       "      <td>1.840550</td>\n",
       "      <td>1.931521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>1.916923</td>\n",
       "      <td>1.931521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>1.851599</td>\n",
       "      <td>1.870263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>1.921325</td>\n",
       "      <td>1.887070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>1.863305</td>\n",
       "      <td>1.871802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>1.832581</td>\n",
       "      <td>1.848455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "parametro        pH_x      pH_y\n",
       "data_coleta                    \n",
       "1979-01-31   1.824549  1.894617\n",
       "1979-02-28   1.813738  1.851076\n",
       "1979-03-31   1.791759  1.856298\n",
       "1980-01-31   1.890850  1.887070\n",
       "1980-02-29   1.840550  1.931521\n",
       "...               ...       ...\n",
       "2018-05-31   1.916923  1.931521\n",
       "2018-08-31   1.851599  1.870263\n",
       "2018-09-30   1.921325  1.887070\n",
       "2018-11-30   1.863305  1.871802\n",
       "2019-09-30   1.832581  1.848455\n",
       "\n",
       "[161 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFmerged3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espaço-temporal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.435556e+10</td>\n",
       "      <td>7.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.550515e+10</td>\n",
       "      <td>6.98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.721531e+10</td>\n",
       "      <td>6.37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.505750e+10</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>127</td>\n",
       "      <td>1.489593e+10</td>\n",
       "      <td>7.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>2.010000e+00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>1.990000e+00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>1.990000e+00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>2.070000e+00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>159</td>\n",
       "      <td>2.060000e+00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tecnica                   parametro amostras          mape  rmse  \\\n",
       "0   Regressão Linear  Coliformes Termotolerantes      127  1.435556e+10  7.35   \n",
       "1   Regressão Linear  Coliformes Termotolerantes      127  1.550515e+10  6.98   \n",
       "2   Regressão Linear  Coliformes Termotolerantes      127  1.721531e+10  6.37   \n",
       "3   Regressão Linear  Coliformes Termotolerantes      127  1.505750e+10  7.18   \n",
       "4   Regressão Linear  Coliformes Termotolerantes      127  1.489593e+10  7.20   \n",
       "..               ...                         ...      ...           ...   ...   \n",
       "75  Regressão Linear                          pH      159  2.010000e+00  0.17   \n",
       "76  Regressão Linear                          pH      159  1.990000e+00  0.17   \n",
       "77  Regressão Linear                          pH      159  1.990000e+00  0.17   \n",
       "78  Regressão Linear                          pH      159  2.070000e+00  0.18   \n",
       "79  Regressão Linear                          pH      159  2.060000e+00  0.18   \n",
       "\n",
       "   lag  \n",
       "0    1  \n",
       "1    2  \n",
       "2    3  \n",
       "3    4  \n",
       "4    5  \n",
       "..  ..  \n",
       "75   6  \n",
       "76   7  \n",
       "77   8  \n",
       "78   9  \n",
       "79  10  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espaço-temporal\n",
    "print('predição espaço-temporal')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','rmse','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    #DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      #(DFmerge['parametro'] == parameter)]\n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET04150') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #if (len(DFmerged1) > len(DFmerged2)):\n",
    "        #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    #else:\n",
    "        #DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    \n",
    "    DFmerged1 = DFmerged1.interpolate(method = 'pad')\n",
    "    DFmerged2 = DFmerged2.interpolate(method = 'pad')\n",
    "    \n",
    "    ##Transforma os dados do coliformes em log\n",
    "    \n",
    "    if (parameter == 'Coliformes Termotolerantes'):\n",
    "        DFmerged1[parameter] = tranformacao_log(DFmerged1[parameter])\n",
    "        DFmerged2[parameter] = tranformacao_log(DFmerged2[parameter])\n",
    "    \n",
    "    DFmerged3 = DFmerged1.merge(DFmerged2, how='inner', on = 'data_coleta')\n",
    "    \n",
    "    dfnovo = DFmerged3\n",
    "    dfnovo = dfnovo.reset_index()\n",
    "        \n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    #Dividindo dataframe\n",
    "    df2050 = DFmerged3.iloc[:,0:1]\n",
    "    df2090 = DFmerged3.iloc[:,1:2]\n",
    "    \n",
    "    train1,train_previsao1, test1 = pegar_dados_coluna_predita_train_test(df2050,0.70,0)\n",
    "    y_test1 = test1\n",
    "    \n",
    "    train2,train_previsao2, test2 = pegar_dados_coluna_predita_train_test(df2090,0.70,0)\n",
    "    y_test2 = test2\n",
    "    \n",
    "    #normalização dos dados\n",
    "    scaler = MinMaxScaler()\n",
    "    train1,test1,testd1 = normalizacao(train1,test1)\n",
    "    train2,test2,testd2 = normalizacao(train2,test2)\n",
    "    \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        \n",
    "                \n",
    "        #Prepara os dados de treinamento\n",
    "        train_X1,train_y1 = prepara_dados(train1, lags,0)  \n",
    "        train_X_lstm1 = train_X1\n",
    "        train_y_lstm1 = train_y1\n",
    "        \n",
    "        train_X2,train_y2 = prepara_dados(train2, lags,0)  \n",
    "        train_X_lstm2 = train_X2\n",
    "        train_y_lstm2 = train_y2\n",
    "                \n",
    "        #Ajusta a dimensão de train_X \n",
    "        nsamples, nx, ny = train_X1.shape\n",
    "        train_X1 = train_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = train_X2.shape\n",
    "        train_X2 = train_X2.reshape((nsamples,nx*ny))\n",
    "    \n",
    "        #Prepara os dados de teste\n",
    "        entradas1 = df2050[len(df2050) - len(test1) - lags:].values\n",
    "        entradas1 = scaler.fit_transform(entradas1)  \n",
    "    \n",
    "        test_X1 = []\n",
    "        for i in range(lags, lags+len(test1)):        \n",
    "            test_X1.append(entradas1[i-lags:i, 0:1])\n",
    "        test_X1 = np.array(test_X1)\n",
    "        \n",
    "        test_X_lstm1 = test_X1\n",
    "        \n",
    "        entradas2 = df2090[len(df2090) - len(test2) - lags:].values\n",
    "        entradas2 = scaler.fit_transform(entradas2)  \n",
    "    \n",
    "        test_X2 = []\n",
    "        for i in range(lags, lags+len(test2)):        \n",
    "            test_X2.append(entradas2[i-lags:i, 0:1])\n",
    "        test_X2 = np.array(test_X2)\n",
    "        \n",
    "        test_X_lstm2 = test_X2\n",
    "                \n",
    "        #Ajusta a dimensão de test_X e train_X\n",
    "        nsamples, nx, ny = test_X1.shape\n",
    "        test_X1 = test_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = test_X2.shape\n",
    "        test_X2 = test_X2.reshape((nsamples,nx*ny))\n",
    "                                                \n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        model.fit(train_X1,train_y1)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X2).reshape(-1, 1) \n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        #print('previsoes',len(previsoes))\n",
    "        #print('testd2',len(testd2))\n",
    "        #print('y_test2',y_test2)\n",
    "        #y_test2[:len(previsoes)]\n",
    "        \n",
    "        #Organiza para salvar no dataframe as series espaço-temporais observado e predito por cada lag e técnica RL.\n",
    "        data = dfnovo.iloc[len(train1):,0:1].values \n",
    "        data = ajusta_lista(data)\n",
    "        observado = ajusta_lista(y_test2)\n",
    "        previsao  = ajusta_lista(previsoes)\n",
    "\n",
    "        dfprevisoes1 = cria_dataframe_obsprevisoes(data,observado,previsao,lags,'Regressão Linear')\n",
    "        df_previsoes = pd.concat([df_previsoes, dfprevisoes1])\n",
    "        \n",
    "        \n",
    "        mape = myutils.mean_absolute_percentage_error(y_test2, previsoes)\n",
    "               \n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged3),\n",
    "                             myutils.mean_absolute_percentage_error(y_test2, previsoes),rmse(y_test2, previsoes),lags)\n",
    "#print(parameter)\n",
    "#mape\n",
    "df_result.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
