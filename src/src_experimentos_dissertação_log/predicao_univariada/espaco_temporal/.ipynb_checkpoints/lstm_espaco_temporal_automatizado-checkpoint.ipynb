{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_files = ''\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi06 = pd.read_csv(str_files + \"cetesb_concatenado06semoutliers.csv\",encoding='utf-8',sep=',',index_col=[0])\n",
    "\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi10 = pd.read_csv(str_files + \"cetesb_concatenado10semoutliers.csv\",encoding='utf-8',sep=',',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Tamanho dos conjuntos originais ----\n",
      "ugrhi06: 503\n",
      "ugrhi10: 502\n",
      "---- Conjunto de dados y igualado ao tamanho de dados do conjunto X ----\n",
      "ugrhi06: 502\n",
      "ugrhi10: 502\n"
     ]
    }
   ],
   "source": [
    "print('---- Tamanho dos conjuntos originais ----')\n",
    "print('ugrhi06:',len(df_ugrhi06))\n",
    "print('ugrhi10:',len(df_ugrhi10))\n",
    "\n",
    "#Seleciona os dados equivalente ao tamanho da URGHI10\n",
    "df_ugrhi06 = df_ugrhi06.iloc[0:len(df_ugrhi10)]\n",
    "\n",
    "#Seleciona os valores da coluna ph da URGHI06, na qual será utilizado para a normalização dos dados quando apresentar o gráfico\n",
    "#train_previsao = ugrhi06['ph'].values\n",
    "#train_previsao = train_previsao.reshape(len(train_previsao),1)\n",
    "\n",
    "print('---- Conjunto de dados y igualado ao tamanho de dados do conjunto X ----')\n",
    "print('ugrhi06:',len(df_ugrhi06))\n",
    "print('ugrhi10:',len(df_ugrhi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_colunas(trainingd,ug):\n",
    "    \n",
    "    if (ug == 6):        \n",
    "        fph      = trainingd.iloc[:,0:1].values\n",
    "        \n",
    "        frame_completo = pd.DataFrame(list(zip(fph)),columns =['ph']) \n",
    "    else:\n",
    "        fph      = trainingd.iloc[:,1:2].values\n",
    "            \n",
    "        frame_completo = pd.DataFrame(list(zip(fph)),columns =['ph'])\n",
    "        \n",
    "    \n",
    "    return frame_completo\n",
    "\n",
    "def seleciona_colunas_od(trainingd,ug):\n",
    "    \n",
    "    if (ug == 6):\n",
    "        \n",
    "        fod      = trainingd.iloc[:,4:5].values\n",
    "        \n",
    "        frame_completo = pd.DataFrame(list(zip(fod)),columns =['od']) \n",
    "    else:\n",
    "        fod      = trainingd.iloc[:,5:6].values\n",
    "            \n",
    "        frame_completo = pd.DataFrame(list(zip(fod)),columns =['od'])\n",
    "        \n",
    "    \n",
    "    return frame_completo  \n",
    "\n",
    "def pega_index_coluna_ugrhi10(p):\n",
    "    \n",
    "    index_coluna = 0\n",
    "    \n",
    "    if (p == 'solido'):\n",
    "        index_coluna = 0\n",
    "    elif (p == 'ph'):\n",
    "        index_coluna = 1\n",
    "    elif (p == 'coliformes'):\n",
    "        index_coluna = 2 \n",
    "    elif (p == 'dbo'):\n",
    "        index_coluna = 3\n",
    "    elif (p == 'fosforo'):\n",
    "        index_coluna == 4\n",
    "    elif (p == 'od'):\n",
    "        index_coluna = 5 \n",
    "    elif (p == 'temperatura'):\n",
    "        index_coluna = 6 \n",
    "    elif (p == 'turbidez'):\n",
    "        index_coluna = 7\n",
    "        \n",
    "    return index_coluna\n",
    "\n",
    "def seleciona_colunas_p(trainingd,p,index_coluna):\n",
    "    fp      = trainingd.iloc[:,index_coluna:index_coluna+1].values\n",
    "        \n",
    "    frame_completo = pd.DataFrame(list(zip(fp)),columns =[p]) \n",
    "    \n",
    "    return frame_completo\n",
    "\n",
    "def pegar_dados_coluna_predita_train_test(trainingd,percent,index_coluna):\n",
    "    data = trainingd.iloc[:,:].values\n",
    "    train = trainingd.iloc[0:int(len(data)*percent),:].values  \n",
    "    train_previsao = trainingd.iloc[0:int(len(data)*percent),index_coluna:index_coluna+1].values\n",
    "    test = trainingd.iloc[len(train):,index_coluna:index_coluna+1].values\n",
    "    \n",
    "    return train,train_previsao, test\n",
    "\n",
    "#Normalização dos dados: Normaliza os dados dentro um intervalo (0 a 1).\n",
    "def normalizacao(train,test):\n",
    "    sc = MinMaxScaler()\n",
    "    testd = test\n",
    "    train = sc.fit_transform(train)\n",
    "    test = sc.fit_transform(test)    \n",
    "    return train,test,testd\n",
    "\n",
    "#Prepara o conjunto de dados em X e y, considerando a janela de visualização (lags).\n",
    "#cy = coluna que será predita\n",
    "def prepara_dados(dados,lags,cy):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(lags, len(dados)):\n",
    "        X.append(dados[i-lags:i,:])\n",
    "        y.append(dados[i, cy])\n",
    "       \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#Calcula o MAPE\n",
    "#Define função para calcular o MAPE\n",
    "#def mape(y_pred,y_true):\n",
    " #   return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mape(y_pred,y_true):\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    '''  \n",
    "    mape_sum = 0\n",
    "    for real,prediction in zip(y_true,y_pred):\n",
    "        mape_sum += (abs((real - prediction))/real)\n",
    "        \n",
    "        print(real)\n",
    "        mape = mape_sum/len(real)\n",
    "    '''\n",
    "    return mape\n",
    "\n",
    "def rmse(y_pred,y_true):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def r2(y_pred,y_true):\n",
    "    rscore = r2_score(y_true,y_pred)\n",
    "    return rscore\n",
    "\n",
    "def rquadrado(y_pred,y_true):\n",
    "    #Soma Total dos Quadrados (STQ): mostra a variação de y em torno da própria média. \n",
    "    #É o somatório das diferenças entre o valor alvo real e sua média elevado ao quadrado.\n",
    "    y_traco = np.mean(y_true)\n",
    "    \n",
    "    print('media y_true:', y_traco)\n",
    "        \n",
    "    stq = 0\n",
    "    \n",
    "    for s in y_true:\n",
    "        a = s - y_traco\n",
    "        st = a * a\n",
    "        stq = stq + st\n",
    "    \n",
    "    print('Soma Total dos Quadrados (STQ):', stq[0])\n",
    "    \n",
    "    #Soma dos Quadrados dos Resíduos (SQU): variação de Y que não é explicada pelo modelo elaborado. \n",
    "    #É o somatório das diferenças entre o valor predito e o valor real elevados ao quadrado.\n",
    "    squ = 0\n",
    "    \n",
    "    y_traco = np.mean(y_pred)\n",
    "    print('media y_pred:', y_traco)\n",
    "    \n",
    "    for n in range(len(y_true)):\n",
    "        a = y_true[n] - y_pred[n]\n",
    "        st = a * a\n",
    "        squ = squ + st\n",
    "        \n",
    "    print('Soma dos Quadrados dos Resíduos (SQU):',squ[0])\n",
    "    print('\\n')\n",
    "    print('Fórmula do R²')\n",
    "    print('\\n')\n",
    "    print('sqr = stq - squ')\n",
    "    sqr = stq[0] - squ[0]\n",
    "    print('R² = sqr/stq')\n",
    "    sqr = sqr/stq[0]\n",
    "    print('\\n')\n",
    "    return sqr\n",
    "\n",
    "def correlacao_determinacao(dtframe,tipo):\n",
    "    \n",
    "    if (tipo == 0): #Treino\n",
    "        resultado = dtframe.corr().previsao_treino.values[1]**2\n",
    "    else: #teste\n",
    "        resultado = dtframe.corr().previsao_teste.values[1]**2\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "def ajusta_array(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def ajusta_lista(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agora é a vez do parâmetro: ph\n",
      "Agora é a vez do parâmetro: coliformes\n",
      "Agora é a vez do parâmetro: dbo\n",
      "Agora é a vez do parâmetro: fosforo\n",
      "Agora é a vez do parâmetro: od\n",
      "Agora é a vez do parâmetro: solido\n",
      "Agora é a vez do parâmetro: temperatura\n",
      "Agora é a vez do parâmetro: turbidez\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parametro</th>\n",
       "      <th>tecnica</th>\n",
       "      <th>mape_treino</th>\n",
       "      <th>rmse_treino</th>\n",
       "      <th>std_rmse_treino</th>\n",
       "      <th>r_quad_treino</th>\n",
       "      <th>mape_teste</th>\n",
       "      <th>rmse_teste</th>\n",
       "      <th>std_rmse_teste</th>\n",
       "      <th>r_quad_teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ph</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coliformes</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>96.37</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.35</td>\n",
       "      <td>127.90</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbo</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>29.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>28.60</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fosforo</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>88.02</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>87.61</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>od</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>solido</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>temperatura</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>turbidez</td>\n",
       "      <td>LSTM (Univar.)</td>\n",
       "      <td>12.33</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     parametro         tecnica  mape_treino  rmse_treino  std_rmse_treino  \\\n",
       "0           ph  LSTM (Univar.)         2.58         0.02             0.00   \n",
       "1   coliformes  LSTM (Univar.)        96.37         2.27             0.08   \n",
       "2          dbo  LSTM (Univar.)        29.66         0.32             0.00   \n",
       "3      fosforo  LSTM (Univar.)        88.02         2.11             0.00   \n",
       "4           od  LSTM (Univar.)        30.26         0.24             0.00   \n",
       "5       solido  LSTM (Univar.)         2.30         0.07             0.00   \n",
       "6  temperatura  LSTM (Univar.)         2.65         0.05             0.00   \n",
       "7     turbidez  LSTM (Univar.)        12.33         0.21             0.00   \n",
       "\n",
       "   r_quad_treino  mape_teste  rmse_teste  std_rmse_teste  r_quad_teste  \n",
       "0           0.10        2.60        0.02            0.00          0.00  \n",
       "1           0.35      127.90        2.66            0.09          0.10  \n",
       "2           0.62       28.60        0.32            0.00          0.31  \n",
       "3           0.34       87.61        2.14            0.01          0.03  \n",
       "4           0.12       27.42        0.21            0.00          0.01  \n",
       "5           0.34        2.46        0.08            0.00          0.02  \n",
       "6           0.09        3.34        0.06            0.00          0.04  \n",
       "7           0.07       14.08        0.24            0.00          0.05  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultado_medio_g = pd.DataFrame()\n",
    "\n",
    "index_coluna = 0\n",
    "\n",
    "parametro = []\n",
    "tecnica   = []\n",
    "\n",
    "#média\n",
    "media_parametro_mape_treino = []\n",
    "media_parametro_rmse_treino = []\n",
    "media_parametro_r_treino    = []\n",
    "    \n",
    "media_parametro_mape_teste  = []\n",
    "media_parametro_rmse_teste  = []\n",
    "media_parametro_r_teste     = []\n",
    "    \n",
    "#desvio_padrão\n",
    "    \n",
    "std_parametro_mape_treino = []\n",
    "std_parametro_rmse_treino = []\n",
    "std_parametro_r_treino    = []\n",
    "    \n",
    "std_parametro_mape_teste  = []\n",
    "std_parametro_rmse_teste  = []\n",
    "std_parametro_r_teste     = []\n",
    "\n",
    "for p in ('ph','coliformes', 'dbo','fosforo','od','solido','temperatura','turbidez'):\n",
    "    \n",
    "    print('Agora é a vez do parâmetro:', p)\n",
    "   \n",
    "    ugrhi06 = seleciona_colunas_p(df_ugrhi06,p,index_coluna)\n",
    "    ugrhi10 = seleciona_colunas_p(df_ugrhi10,p,pega_index_coluna_ugrhi10(p))\n",
    "   \n",
    "    index_coluna = index_coluna + 1\n",
    "\n",
    "    df_resultados_treino = pd.DataFrame()\n",
    "    df_resultados_teste  = pd.DataFrame()\n",
    "    df_resultados        = pd.DataFrame()\n",
    "    \n",
    "    media_lag_mape_treino = []\n",
    "    media_lag_rmse_treino = []\n",
    "    media_lag_r_treino    = []\n",
    "        \n",
    "    media_lag_mape_teste = []\n",
    "    media_lag_rmse_teste = []\n",
    "    media_lag_r_teste    = []\n",
    "    \n",
    "    for l in range(1, 16):\n",
    "    \n",
    "        lags = l\n",
    "    \n",
    "    #seleciona os dados\n",
    "    \n",
    "        train06,train_previsao06, test06 = pegar_dados_coluna_predita_train_test(ugrhi06,0.70,0) \n",
    "        train10,train_previsao10, test10 = pegar_dados_coluna_predita_train_test(ugrhi10,0.70,0) \n",
    "\n",
    "        #normalização dos dados\n",
    "        train06,test06,testd06 = normalizacao(train06,test06)\n",
    "        train10,test10,testd10 = normalizacao(train10,test10)\n",
    "\n",
    "        normalizador_previsao = MinMaxScaler()\n",
    "        sc = MinMaxScaler()\n",
    "        normalizador_previsao.fit_transform(train_previsao06)\n",
    "\n",
    "        #Prepara os dados de treinamento -ugrhi06\n",
    "        #Vai predizer o valor da coluna 4 (valor ph)\n",
    "        train_X06, train_y06 = prepara_dados(train06, lags,0)\n",
    "\n",
    "        #Prepara os dados de teste\n",
    "        entradas06 = ugrhi06[len(ugrhi06) - len(test06) - lags:].values\n",
    "        entradas06 = sc.fit_transform(entradas06)   \n",
    "\n",
    "        test_X06 = []\n",
    "        for i in range(lags, lags+len(test06)):\n",
    "            test_X06.append(entradas06[i-lags:i, 0:1])\n",
    "        test_X06 = np.array(test_X06)\n",
    "\n",
    "        #Prepara os dados de treinamento -ugrhi10\n",
    "        #Aqui vamos pegar test_X10.\n",
    "        train_X10, train_y10 = prepara_dados(train10, lags,0)\n",
    "\n",
    "        #Prepara os dados de teste\n",
    "        entradas10 = ugrhi10[len(ugrhi10) - len(test10) - lags:].values\n",
    "        entradas10 = sc.fit_transform(entradas10)   \n",
    "\n",
    "        test_X10 = []\n",
    "        for i in range(lags, lags+len(test10)):\n",
    "            test_X10.append(entradas10[i-lags:i, 0:1])\n",
    "        test_X10 = np.array(test_X10)\n",
    "        \n",
    "        media_simulador_mape_treino = []\n",
    "        media_simulador_rmse_treino = []\n",
    "        media_simulador_r_treino    = []\n",
    "\n",
    "        media_simulador_mape_teste  = []\n",
    "        media_simulador_rmse_teste  = []\n",
    "        media_simulador_r_teste     = []\n",
    "        \n",
    "        for r in range(0,6):\n",
    "    \n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units = 10, input_shape = (train_X06.shape[1], 1)))\n",
    "            model.add(Dense(21, activation = 'relu'))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(1, activation = 'sigmoid'))\n",
    "            model.compile(loss = 'mean_absolute_error', optimizer = 'adam',\n",
    "                          metrics = ['mean_absolute_error'])\n",
    "\n",
    "            es = EarlyStopping(monitor='val_loss', patience = 3, verbose=0)\n",
    "\n",
    "\n",
    "            #Treina o modelo\n",
    "            history = model.fit(train_X06, train_y06, validation_data=(test_X10, test10), batch_size = 32, epochs = 2000, \n",
    "                                callbacks=[es], verbose=0)\n",
    "\n",
    "            #Treina o modelo\n",
    "            #model.fit(train_X06, train_y06, batch_size = 32, epochs = 100)\n",
    "\n",
    "            #Dados de teste\n",
    "            previsoes = model.predict(test_X10)\n",
    "            #previsoes = previsoes.reshape(-1, 1)\n",
    "            previsoes = normalizador_previsao.inverse_transform(previsoes)\n",
    "\n",
    "            #print('Teste - Gráficos com lag', l)\n",
    "            '''\n",
    "            #Plotagem do gráfico\n",
    "            plt.plot(testd10,color='red',label = 'Observado')\n",
    "            plt.plot(previsoes,color='blue',label = 'Previsoes')\n",
    "            plt.xlabel('Tempo')\n",
    "            plt.ylabel('Valor pH')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            #Dados de treino\n",
    "            previsoes_treino = model.predict(train_X10)\n",
    "            previsoes_treino = previsoes_treino.reshape(-1, 1)\n",
    "            previsoes_treino = normalizador_previsao.inverse_transform(previsoes_treino)\n",
    "\n",
    "            treino = train_previsao10[lags: len(previsoes_treino) + lags, :]\n",
    "            observado_test = testd10\n",
    "\n",
    "            observado_treino = train_previsao10  \n",
    "\n",
    "            #print('Treinamento - Gráficos com lag', l)\n",
    "            '''\n",
    "            #Plotagem do gráfico\n",
    "            plt.plot(train_previsao10,color='red',label = 'Observado')\n",
    "            plt.plot(previsoes_treino,color='blue',label = 'Previsoes')\n",
    "            plt.xlabel('Tempo')\n",
    "            plt.ylabel('Valor pH')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            treino         = ajusta_array(treino)\n",
    "            observado_test = ajusta_array(observado_test)\n",
    "\n",
    "            #Calculo do erro da previsão MAPE, RMSE e R²\n",
    "\n",
    "            observado_treino_d = observado_treino\n",
    "            previsoes_treino_d = previsoes_treino\n",
    "            previsoes_d        = previsoes\n",
    "\n",
    "            mape_treino_d        = round(mape(previsoes_treino,treino),4)\n",
    "            rmse_treino_d        = round(rmse(previsoes_treino,treino),4)\n",
    "            #r_treino_d           = round(r2(previsoes_treino,treino),4)\n",
    "\n",
    "            mape_teste_d        = round(mape(previsoes,observado_test),4)\n",
    "            rmse_teste_d        = round(rmse(previsoes,observado_test),4)\n",
    "            #r_teste_d           = round(r2(previsoes,observado_test),4) \n",
    "\n",
    "            df_corr_determinacao_treino = pd.DataFrame()\n",
    "            df_corr_determinacao_teste  = pd.DataFrame()\n",
    "\n",
    "            #Calcula o coeficiente de determinação\n",
    "            dict = {'previsao_treino': ajusta_lista(previsoes_treino), 'treino': ajusta_array(treino)} \n",
    "\n",
    "            df_treino = pd.DataFrame(dict)\n",
    "            dframes_treino = [df_corr_determinacao_treino,df_treino]\n",
    "            df_corr_determinacao_treino = pd.concat(dframes_treino)\n",
    "\n",
    "            dict = {'previsao_teste': ajusta_lista(previsoes), 'teste': ajusta_array(observado_test)} \n",
    "\n",
    "            df_teste = pd.DataFrame(dict)\n",
    "            dframes_teste = [df_corr_determinacao_teste,df_teste]\n",
    "            df_corr_determinacao_teste = pd.concat(dframes_teste)\n",
    "\n",
    "            r_treino_d = []\n",
    "            r_teste_d  = []\n",
    "\n",
    "            r_treino_d.append(round(correlacao_determinacao(df_corr_determinacao_treino,0),4))\n",
    "            r_teste_d.append(round(correlacao_determinacao(df_corr_determinacao_teste,1),4))\n",
    "            \n",
    "            media_simulador_mape_treino.append(np.mean(mape_treino_d))\n",
    "            media_simulador_rmse_treino.append(np.mean(rmse_treino_d))\n",
    "            media_simulador_r_treino.append(np.mean(r_treino_d))\n",
    "            \n",
    "            media_simulador_mape_teste.append(np.mean(mape_teste_d))\n",
    "            media_simulador_rmse_teste.append(np.mean(rmse_teste_d))\n",
    "            media_simulador_r_teste.append(np.mean(r_teste_d))\n",
    "            \n",
    "            \n",
    "    \n",
    "        media_lag_mape_treino.append(np.mean(media_simulador_mape_treino))\n",
    "        media_lag_rmse_treino.append(np.mean(media_simulador_rmse_treino))\n",
    "        media_lag_r_treino.append(np.mean(media_simulador_r_treino))\n",
    "        \n",
    "        media_lag_mape_teste.append(np.mean(media_simulador_mape_teste))\n",
    "        media_lag_rmse_teste.append(np.mean(media_simulador_rmse_teste))\n",
    "        media_lag_r_teste.append(np.mean(media_simulador_r_teste))\n",
    "        \n",
    "                \n",
    "    #média\n",
    "    media_parametro_mape_treino.append(np.mean(media_lag_mape_treino))\n",
    "    media_parametro_rmse_treino.append(np.mean(media_lag_rmse_treino))\n",
    "    media_parametro_r_treino.append(np.mean(media_lag_r_treino))\n",
    "    \n",
    "    media_parametro_mape_teste.append(np.mean(media_lag_mape_teste))\n",
    "    media_parametro_rmse_teste.append(np.mean(media_lag_rmse_teste))\n",
    "    media_parametro_r_teste.append(np.mean(media_lag_r_teste))\n",
    "        \n",
    "    #desvio_padrão\n",
    "    \n",
    "    #std_parametro_mape_treino.append(np.std(media_lag_mape_treino))\n",
    "    std_parametro_rmse_treino.append(np.std(media_lag_rmse_treino))\n",
    "    #std_parametro_r_treino.append(np.std(media_lag_r_treino))\n",
    "    \n",
    "    #std_parametro_mape_teste.append(np.std(media_lag_mape_teste))\n",
    "    std_parametro_rmse_teste.append(np.std(media_lag_rmse_teste))\n",
    "    #std_parametro_r_teste.append(np.std(media_lag_r_teste))\n",
    "        \n",
    "    parametro.append(p)\n",
    "    tecnica.append('LSTM (Univar.)')\n",
    "    \n",
    "        \n",
    "dict = {'parametro': parametro,\n",
    "         'tecnica': tecnica,\n",
    "        'mape_treino':  media_parametro_mape_treino,  \n",
    "        'rmse_treino':  media_parametro_rmse_treino, 'std_rmse_treino':  std_parametro_rmse_treino,\n",
    "        'r_quad_treino':media_parametro_r_treino,    \n",
    "        'mape_teste':   media_parametro_mape_teste,   \n",
    "        'rmse_teste':   media_parametro_rmse_teste,  'std_rmse_teste':   std_parametro_rmse_teste,\n",
    "        'r_quad_teste': media_parametro_r_teste}\n",
    "   \n",
    "df_resultado_final = pd.DataFrame(dict)\n",
    "\n",
    "dframes = [df_resultado_medio_g,df_resultado_final]\n",
    "df_resultado_medio_g = pd.concat(dframes)\n",
    "\n",
    "df_resultado_medio_g.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado_medio_g.to_csv (r'/home/anderson/Downloads/src_experimentos_dissertação/resultados_log_csv/espaco_temporal_lstm_univariada.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
