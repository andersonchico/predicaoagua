{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "#sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import utilidades as myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_group_data(dataset, parameter, range_upper = 1,range_lower = 1):\n",
    "    \n",
    "    q1, q3 = np.percentile(dataset[parameter],[25,75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q3 - range_upper*(1.5 * iqr)  \n",
    "    upper_bound = q3 + range_upper*(1.5 * iqr)  \n",
    "\n",
    "    # Deleting lower bound and upper bound from the dataset LinkTT2\n",
    "    #dataset = dataset.loc[(dataset[parameter] >= lower_bound) & \n",
    "                                              #(dataset[parameter] <= upper_bound)]\n",
    "    dataset.interpolate()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def resultado(df,tecnica,parameter,amostras,metrica,lag):\n",
    "    \n",
    "    df.loc[len(df)]= [tecnica,parameter,amostras,round(metrica,2),lag]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>170</td>\n",
       "      <td>33.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>170</td>\n",
       "      <td>53.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>170</td>\n",
       "      <td>33.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>170</td>\n",
       "      <td>34.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>170</td>\n",
       "      <td>33.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>207</td>\n",
       "      <td>1.85</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>207</td>\n",
       "      <td>1.83</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>207</td>\n",
       "      <td>2.51</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>207</td>\n",
       "      <td>1.83</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>207</td>\n",
       "      <td>1.80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tecnica                   parametro amostras   mape lag\n",
       "0    Regressão Linear  Coliformes Termotolerantes      170  33.37   1\n",
       "1       Random Forest  Coliformes Termotolerantes      170  53.37   1\n",
       "2                 MLP  Coliformes Termotolerantes      170  33.76   1\n",
       "3                LSTM  Coliformes Termotolerantes      170  34.94   1\n",
       "4    Regressão Linear  Coliformes Termotolerantes      170  33.37   2\n",
       "..                ...                         ...      ...    ...  ..\n",
       "283              LSTM                          pH      207   1.85   8\n",
       "284  Regressão Linear                          pH      207   1.83   9\n",
       "285     Random Forest                          pH      207   2.51   9\n",
       "286               MLP                          pH      207   1.83   9\n",
       "287              LSTM                          pH      207   1.80   9\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    DFmerged = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "\n",
    "    \n",
    "\n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    DFmerged = DFmerged[DFmerged['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged = clean_group_data(DFmerged, 'valor')\n",
    "    \n",
    "    DFmerged['data_coleta'] = pd.to_datetime(DFmerged['data_coleta'])\n",
    "    DFmerged.index = DFmerged['data_coleta']    \n",
    "    DFmerged = DFmerged.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged = DFmerged.loc['1979-01-31':]\n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    #DFmerged = scaler.fit_transform(np.log(DFmerged + 0.0000001))\n",
    "#     DFmerged = scaler.fit_transform()\n",
    "\n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    for lag in range(1,10):\n",
    "\n",
    "        X  = DFmerged[:-lag]\n",
    "        y  = DFmerged[lag:]\n",
    "\n",
    "\n",
    "        dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "        dataset.columns = ['X','y']\n",
    "        dataset.dropna(inplace=True)\n",
    "\n",
    "        train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "        train_y = scaler.fit_transform(np.log(np.array(dataset['y']).reshape(len(dataset), 1) + 0.000000001))\n",
    "        \n",
    "        #tamanho_treino = int(len(train_X)*0.7)\n",
    "        tamanho_teste  = int(len(train_y)*0.3)\n",
    "\n",
    "        #Desnormalização train_y(teste)\n",
    "        y_teste = scaler.inverse_transform(train_y[-tamanho_teste:])\n",
    "\n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        #model.fit(train_X[:-40],train_y[:-40])\n",
    "        model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "        score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "        #Dados de teste\n",
    "        #previsoes = model.predict(train_X[-40:])\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        #df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),myutils.mean_absolute_percentage_error(train_y[-40:], previsoes))\n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),lag)\n",
    "        \n",
    "        \n",
    "        #print(parameter, len(DFmerged),'MAPE',str(myutils.mean_absolute_percentage_error(train_y[-40:], previsoes)))\n",
    "\n",
    "        #Random Forest\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "        score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes.reshape(-1, 1))\n",
    "\n",
    "        df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),lag)\n",
    "\n",
    "        #MLP\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = 10, activation = 'relu', input_dim = train_X[:-tamanho_teste].shape[1]))\n",
    "        model.add(Dense(units = 21, activation = 'relu'))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste], validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]),  batch_size = 32, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))  \n",
    "\n",
    "        df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged),np.mean(media_previsoes),lag)\n",
    "\n",
    "\n",
    "        #LSTM\n",
    "\n",
    "        train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "        train_y = np.reshape(train_y, (train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 10, input_shape = (train_X[:-tamanho_teste].shape[1], 1)))\n",
    "        model.add(Dense(21, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste],validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]), batch_size = 32, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))\n",
    "\n",
    "        df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged),np.mean(media_previsoes),lag)\n",
    "\n",
    "        '''\n",
    "        g_X = train_X.reshape((train_X.shape[0],train_X.shape[1]))\n",
    "        g_previsoes = concatenate((previsoes,g_X[-tamanho_teste:]),axis=1)\n",
    "        g_previsoes = scaler.inverse_transform(g_previsoes)\n",
    "        #g_previsoes = g_previsoes[:,1]\n",
    "\n",
    "        g_y   = train_y.reshape(len(train_y),1)\n",
    "        g_obs = concatenate((g_y[-tamanho_teste:],g_X[-tamanho_teste:]),axis=1)\n",
    "        g_obs = scaler.inverse_transform(g_obs)\n",
    "       # g_obs = g_obs[:,1]\n",
    "\n",
    "        #plt.clf()\n",
    "        plt.plot(g_previsoes,label=\"model\")\n",
    "        plt.plot(g_obs,label=\"Observed\")\n",
    "        plt.legend()\n",
    "        plt.title(parameter)\n",
    "        plt.savefig(parameter+\".png\")\n",
    "        plt.close(\"all\")\n",
    "        ''' \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/temporal_interpolacao_lag.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espaço-temporal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>23.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>29.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>28.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>28.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>23.66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.91</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>1.04</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>1.05</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.92</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tecnica                   parametro amostras   mape lag\n",
       "0    Regressão Linear  Coliformes Termotolerantes      151  23.70   1\n",
       "1       Random Forest  Coliformes Termotolerantes      151  29.61   1\n",
       "2                 MLP  Coliformes Termotolerantes      151  28.71   1\n",
       "3                LSTM  Coliformes Termotolerantes      151  28.51   1\n",
       "4    Regressão Linear  Coliformes Termotolerantes      151  23.66   2\n",
       "..                ...                         ...      ...    ...  ..\n",
       "283              LSTM                          pH      167   0.91   8\n",
       "284  Regressão Linear                          pH      167   1.04   9\n",
       "285     Random Forest                          pH      167   1.05   9\n",
       "286               MLP                          pH      167   0.88   9\n",
       "287              LSTM                          pH      167   0.92   9\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espaço-temporal\n",
    "print('predição espaço-temporal')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    if (len(DFmerged1) > len(DFmerged2)):\n",
    "        DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    else:\n",
    "        DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    #DFmerged = scaler.fit_transform(np.log(DFmerged + 0.0000001))\n",
    "#     DFmerged = scaler.fit_transform()\n",
    "\n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    for lag in range(1,10):\n",
    "\n",
    "        X  = DFmerged1[:-lag]\n",
    "        y  = DFmerged2[lag:]\n",
    "\n",
    "\n",
    "        dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "        dataset.columns = ['X','y']\n",
    "        dataset.dropna(inplace=True)\n",
    "\n",
    "        train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "        train_y = scaler.fit_transform(np.log(np.array(dataset['y']).reshape(len(dataset), 1) + 0.000000001))\n",
    "        \n",
    "        #tamanho_treino = int(len(train_X)*0.7)\n",
    "        tamanho_teste  = int(len(train_y)*0.3)\n",
    "\n",
    "        #Desnormalização train_y(teste)\n",
    "        y_teste = scaler.inverse_transform(train_y[-tamanho_teste:])\n",
    "\n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        #model.fit(train_X[:-40],train_y[:-40])\n",
    "        model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "        score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "        #Dados de teste\n",
    "        #previsoes = model.predict(train_X[-40:])\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        #df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),myutils.mean_absolute_percentage_error(train_y[-40:], previsoes))\n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged1),myutils.mean_absolute_percentage_error(y_teste, previsoes),lag)\n",
    "        \n",
    "        \n",
    "        #print(parameter, len(DFmerged),'MAPE',str(myutils.mean_absolute_percentage_error(train_y[-40:], previsoes)))\n",
    "\n",
    "        #Random Forest\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "        score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes.reshape(-1, 1))\n",
    "\n",
    "        df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),lag)\n",
    "\n",
    "        #MLP\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = 10, activation = 'relu', input_dim = train_X[:-tamanho_teste].shape[1]))\n",
    "        model.add(Dense(units = 21, activation = 'relu'))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste], validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]),  batch_size = 32, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))  \n",
    "\n",
    "        df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged1),np.mean(media_previsoes),lag)\n",
    "\n",
    "\n",
    "        #LSTM\n",
    "\n",
    "        train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "        train_y = np.reshape(train_y, (train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 10, input_shape = (train_X[:-tamanho_teste].shape[1], 1)))\n",
    "        model.add(Dense(21, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste],validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]), batch_size = 32, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))\n",
    "\n",
    "        df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged1),np.mean(media_previsoes),lag)\n",
    "\n",
    "         \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/espaco_temporal_ausentes_deletados_lag.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espacial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>24.05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>29.05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>30.94</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>28.83</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>17.86</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>19.06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>19.57</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>19.50</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>37.63</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>38.74</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>37.67</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>37.63</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>17.17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.75</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.96</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>8.71</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>2.95</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>7.33</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>10.34</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>7.96</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>7.32</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>0.45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>0.97</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>2.68</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>3.12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>2.24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>3.10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>1.19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.90</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tecnica                   parametro amostras   mape lag\n",
       "0   Regressão Linear  Coliformes Termotolerantes      151  24.05    \n",
       "1      Random Forest  Coliformes Termotolerantes      151  29.05    \n",
       "2                MLP  Coliformes Termotolerantes      151  30.94    \n",
       "3               LSTM  Coliformes Termotolerantes      151  28.83    \n",
       "4   Regressão Linear         Oxigênio Dissolvido      186  17.86    \n",
       "5      Random Forest         Oxigênio Dissolvido      186  19.06    \n",
       "6                MLP         Oxigênio Dissolvido      186  19.57    \n",
       "7               LSTM         Oxigênio Dissolvido      186  19.50    \n",
       "8   Regressão Linear                    Turbidez      176  37.63    \n",
       "9      Random Forest                    Turbidez      176  38.74    \n",
       "10               MLP                    Turbidez      176  37.67    \n",
       "11              LSTM                    Turbidez      176  37.63    \n",
       "12  Regressão Linear               Fósforo Total      192  17.17    \n",
       "13     Random Forest               Fósforo Total      192  16.75    \n",
       "14               MLP               Fósforo Total      192  16.08    \n",
       "15              LSTM               Fósforo Total      192  16.96    \n",
       "16  Regressão Linear                Sólido Total      197   8.71    \n",
       "17     Random Forest                Sólido Total      197   2.95    \n",
       "18               MLP                Sólido Total      197   7.33    \n",
       "19              LSTM                Sólido Total      197  10.34    \n",
       "20  Regressão Linear                 DBO (5, 20)      161   7.96    \n",
       "21     Random Forest                 DBO (5, 20)      161   7.32    \n",
       "22               MLP                 DBO (5, 20)      161   0.45    \n",
       "23              LSTM                 DBO (5, 20)      161   0.97    \n",
       "24  Regressão Linear         Temperatura da Água      195   2.68    \n",
       "25     Random Forest         Temperatura da Água      195   3.12    \n",
       "26               MLP         Temperatura da Água      195   2.24    \n",
       "27              LSTM         Temperatura da Água      195   3.10    \n",
       "28  Regressão Linear                          pH      167   1.00    \n",
       "29     Random Forest                          pH      167   1.19    \n",
       "30               MLP                          pH      167   0.88    \n",
       "31              LSTM                          pH      167   0.90    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espacial\n",
    "print('predição espacial')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    if (len(DFmerged1) > len(DFmerged2)):\n",
    "        DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    else:\n",
    "        DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    #DFmerged = scaler.fit_transform(np.log(DFmerged + 0.0000001))\n",
    "#     DFmerged = scaler.fit_transform()\n",
    "\n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "        \n",
    "    X  = DFmerged1[:]\n",
    "    y  = DFmerged2[:]\n",
    "\n",
    "\n",
    "    dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "    dataset.columns = ['X','y']\n",
    "    dataset.dropna(inplace=True)\n",
    "\n",
    "    train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "    train_y = scaler.fit_transform(np.log(np.array(dataset['y']).reshape(len(dataset), 1) + 0.000000001))\n",
    "        \n",
    "    #tamanho_treino = int(len(train_X)*0.7)\n",
    "    tamanho_teste  = int(len(train_y)*0.3)\n",
    "\n",
    "    #Desnormalização train_y(teste)\n",
    "    y_teste = scaler.inverse_transform(train_y[-tamanho_teste:])\n",
    "\n",
    "    #Regressão Linear\n",
    "    model = LinearRegression(normalize=False)\n",
    "\n",
    "    #model.fit(train_X[:-40],train_y[:-40])\n",
    "    model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "    score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "    #Dados de teste\n",
    "    #previsoes = model.predict(train_X[-40:])\n",
    "    previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "    previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "    #df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),myutils.mean_absolute_percentage_error(train_y[-40:], previsoes))\n",
    "    df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),'')\n",
    "        \n",
    "        \n",
    "    #print(parameter, len(DFmerged),'MAPE',str(myutils.mean_absolute_percentage_error(train_y[-40:], previsoes)))\n",
    "\n",
    "    #Random Forest\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "    score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "    #Dados de teste\n",
    "    previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "    previsoes = scaler.inverse_transform(previsoes.reshape(-1, 1))\n",
    "\n",
    "    df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),'')\n",
    "\n",
    "    #MLP\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, activation = 'relu', input_dim = train_X[:-tamanho_teste].shape[1]))\n",
    "    model.add(Dense(units = 21, activation = 'relu'))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste], validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]),  batch_size = 32, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "    #Dados de teste\n",
    "    media_previsoes = []\n",
    "    for r in range(0,6):\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))  \n",
    "\n",
    "    df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged1),np.mean(media_previsoes),'')\n",
    "\n",
    "\n",
    "    #LSTM\n",
    "\n",
    "    train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "    train_y = np.reshape(train_y, (train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 10, input_shape = (train_X[:-tamanho_teste].shape[1], 1)))\n",
    "    model.add(Dense(21, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste],validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]), batch_size = 32, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "    #Dados de teste\n",
    "    media_previsoes = []\n",
    "    for r in range(0,6):\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))\n",
    "\n",
    "    df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged1),np.mean(media_previsoes),'')\n",
    "\n",
    "         \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/espacial_ausentes_deletados.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodode</th>\n",
       "      <th>periodoate</th>\n",
       "      <th>cod_interaguas</th>\n",
       "      <th>tipo_rede</th>\n",
       "      <th>UGRHI</th>\n",
       "      <th>codigo_ponto</th>\n",
       "      <th>status_ponto</th>\n",
       "      <th>data_coleta</th>\n",
       "      <th>hora_coleta</th>\n",
       "      <th>parametro</th>\n",
       "      <th>...</th>\n",
       "      <th>inicio_operacao</th>\n",
       "      <th>fim_operacao</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Localizacao</th>\n",
       "      <th>Captacao</th>\n",
       "      <th>municipio</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>01/01/1978</td>\n",
       "      <td>12:00</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>01/02/1978</td>\n",
       "      <td>12:00</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>01/03/1978</td>\n",
       "      <td>12:00</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>01/04/1978</td>\n",
       "      <td>12:00</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>01/05/1978</td>\n",
       "      <td>12:00</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>24/05/2018</td>\n",
       "      <td>12:44</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>11/07/2018</td>\n",
       "      <td>11:10</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>13/09/2018</td>\n",
       "      <td>11:50</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>29/11/2018</td>\n",
       "      <td>11:50</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>01/01/1974</td>\n",
       "      <td>28/12/2019</td>\n",
       "      <td>110</td>\n",
       "      <td>Rede Básica</td>\n",
       "      <td>06 - ALTO TIÊTE</td>\n",
       "      <td>TIET02050</td>\n",
       "      <td>Ativo</td>\n",
       "      <td>09/01/2019</td>\n",
       "      <td>11:50</td>\n",
       "      <td>pH</td>\n",
       "      <td>...</td>\n",
       "      <td>01/01/1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 33 54</td>\n",
       "      <td>46 00 57</td>\n",
       "      <td>750</td>\n",
       "      <td>Ponte na SP-088 que liga Mogi das Cruzes a Sal...</td>\n",
       "      <td>N</td>\n",
       "      <td>BIRITIBA MIRIM</td>\n",
       "      <td>-23565000.0</td>\n",
       "      <td>-46015833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      periodode  periodoate  cod_interaguas    tipo_rede            UGRHI  \\\n",
       "460  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "461  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "462  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "463  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "464  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "..          ...         ...             ...          ...              ...   \n",
       "744  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "745  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "746  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "747  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "748  01/01/1974  28/12/2019             110  Rede Básica  06 - ALTO TIÊTE   \n",
       "\n",
       "    codigo_ponto status_ponto data_coleta hora_coleta parametro  ...  \\\n",
       "460    TIET02050        Ativo  01/01/1978       12:00        pH  ...   \n",
       "461    TIET02050        Ativo  01/02/1978       12:00        pH  ...   \n",
       "462    TIET02050        Ativo  01/03/1978       12:00        pH  ...   \n",
       "463    TIET02050        Ativo  01/04/1978       12:00        pH  ...   \n",
       "464    TIET02050        Ativo  01/05/1978       12:00        pH  ...   \n",
       "..           ...          ...         ...         ...       ...  ...   \n",
       "744    TIET02050        Ativo  24/05/2018       12:44        pH  ...   \n",
       "745    TIET02050        Ativo  11/07/2018       11:10        pH  ...   \n",
       "746    TIET02050        Ativo  13/09/2018       11:50        pH  ...   \n",
       "747    TIET02050        Ativo  29/11/2018       11:50        pH  ...   \n",
       "748    TIET02050        Ativo  09/01/2019       11:50        pH  ...   \n",
       "\n",
       "    inicio_operacao  fim_operacao   Latitude  Longitude Altitude  \\\n",
       "460      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "461      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "462      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "463      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "464      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "..              ...           ...        ...        ...      ...   \n",
       "744      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "745      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "746      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "747      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "748      01/01/1977           NaN  23 33 54   46 00 57       750   \n",
       "\n",
       "                                           Localizacao Captacao  \\\n",
       "460  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "461  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "462  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "463  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "464  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "..                                                 ...      ...   \n",
       "744  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "745  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "746  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "747  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "748  Ponte na SP-088 que liga Mogi das Cruzes a Sal...        N   \n",
       "\n",
       "          municipio         Lat       Long  \n",
       "460  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "461  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "462  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "463  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "464  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "..              ...         ...        ...  \n",
       "744  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "745  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "746  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "747  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "748  BIRITIBA MIRIM -23565000.0  -46015833  \n",
       "\n",
       "[289 rows x 29 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                     (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    #DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      #(DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "    \n",
    "    DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    #DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    #DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    #DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "    \n",
    "    '''\n",
    "    DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "DFmerged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
