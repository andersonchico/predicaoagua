{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "#sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import utilidades as myutils\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_group_data(dataset, parameter, range_upper = 1,range_lower = 1):\n",
    "    \n",
    "    q1, q3 = np.percentile(dataset[parameter],[25,75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q3 - range_upper*(1.5 * iqr)  \n",
    "    upper_bound = q3 + range_upper*(1.5 * iqr)  \n",
    "\n",
    "    # Deleting lower bound and upper bound from the dataset LinkTT2\n",
    "    dataset = dataset.loc[(dataset[parameter] >= lower_bound) & \n",
    "                                              (dataset[parameter] <= upper_bound)]\n",
    "    #dataset.interpolate()\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def resultado(df,tecnica,parameter,amostras,metrica,lag):\n",
    "    \n",
    "    df.loc[len(df)]= [tecnica,parameter,amostras,round(metrica,2),lag]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "#Prepara o conjunto de dados em X e y, considerando a janela de visualização (lags).\n",
    "#cy = coluna que será predita\n",
    "def prepara_dados(dados,lags,cy):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(lags, len(dados)):\n",
    "        X.append(dados[i-lags:i,:])\n",
    "        y.append(dados[i, cy])\n",
    "       \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def pegar_dados_coluna_predita_train_test(trainingd,percent,index_coluna):\n",
    "    data = trainingd.iloc[:,:].values\n",
    "    train = trainingd.iloc[0:int(len(data)*percent),:].values\n",
    "    train_previsao = trainingd.iloc[0:int(len(data)*percent),index_coluna:index_coluna+1].values\n",
    "    test = trainingd.iloc[len(train):,index_coluna:index_coluna+1].values \n",
    "    '''\n",
    "    print('Nº observações:', len(data))\n",
    "    print('treino:',len(train))\n",
    "    print('teste:',len(test))\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return train,train_previsao, test\n",
    "\n",
    "#Normalização dos dados: Normaliza os dados dentro um intervalo (0 a 1).\n",
    "def normalizacao(train,test):\n",
    "    sc = MinMaxScaler()\n",
    "    testd = test\n",
    "    train = sc.fit_transform(train)\n",
    "    test = sc.fit_transform(test)    \n",
    "    return train,test,testd\n",
    "\n",
    "def tranformacao_log(valores_parametro):\n",
    "   \n",
    "    valores_log = []\n",
    "   \n",
    "    for i in range(len(valores_parametro)):\n",
    "        #print(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "        valores_log.append(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "       \n",
    "    return valores_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coliformes Termotolerantes\n",
      "Oxigênio Dissolvido\n",
      "Turbidez\n",
      "Fósforo Total\n",
      "Sólido Total\n",
      "DBO (5, 20)\n",
      "Temperatura da Água\n",
      "pH\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>55.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>55.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>50.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>52.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>41.82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.66</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.69</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.67</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>1.54</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tecnica                   parametro amostras   mape lag\n",
       "0    Regressão Linear  Coliformes Termotolerantes      151  55.41   1\n",
       "1       Random Forest  Coliformes Termotolerantes      151  55.40   1\n",
       "2                 MLP  Coliformes Termotolerantes      151  50.55   1\n",
       "3                LSTM  Coliformes Termotolerantes      151  52.56   1\n",
       "4    Regressão Linear  Coliformes Termotolerantes      151  41.82   2\n",
       "..                ...                         ...      ...    ...  ..\n",
       "315              LSTM                          pH      179   1.54   9\n",
       "316  Regressão Linear                          pH      179   1.66  10\n",
       "317     Random Forest                          pH      179   1.69  10\n",
       "318               MLP                          pH      179   1.67  10\n",
       "319              LSTM                          pH      179   1.54  10\n",
       "\n",
       "[320 rows x 5 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    DFmerged = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    print(parameter)\n",
    "     \n",
    "    DFmerged = clean_group_data(DFmerged, 'valor')\n",
    "    \n",
    "    DFmerged['data_coleta'] = pd.to_datetime(DFmerged['data_coleta'])\n",
    "    DFmerged.index = DFmerged['data_coleta']    \n",
    "    DFmerged = DFmerged.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged = DFmerged.loc['1979-01-31':]\n",
    "    \n",
    "    DFmerged = DFmerged.interpolate(method = 'pad')\n",
    "    \n",
    "    DFmerged[parameter] = tranformacao_log(DFmerged[parameter])\n",
    "        \n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    #seleciona os dados\n",
    "    \n",
    "    train,train_previsao, test = pegar_dados_coluna_predita_train_test(DFmerged,0.70,0)\n",
    "    y_test = test\n",
    "        \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        #normalização dos dados\n",
    "        scaler = MinMaxScaler()\n",
    "        train,test,testd = normalizacao(train,test)\n",
    "                \n",
    "        #Prepara os dados de treinamento\n",
    "        train_X,train_y = prepara_dados(train, lags,0)  \n",
    "        train_X_lstm = train_X\n",
    "        train_y_lstm = train_y\n",
    "                \n",
    "        #Ajusta a dimensão de train_X \n",
    "        nsamples, nx, ny = train_X.shape\n",
    "        train_X = train_X.reshape((nsamples,nx*ny))\n",
    "    \n",
    "        #Prepara os dados de teste\n",
    "        entradas = DFmerged[len(DFmerged) - len(test) - lags:].values\n",
    "        entradas = scaler.fit_transform(entradas)  \n",
    "    \n",
    "        test_X = []\n",
    "        for i in range(lags, lags+len(test)):        \n",
    "            test_X.append(entradas[i-lags:i, 0:1])\n",
    "        test_X = np.array(test_X)\n",
    "        \n",
    "        test_X_lstm = test_X\n",
    "                \n",
    "        #Ajusta a dimensão de test_X e train_X\n",
    "        nsamples, nx, ny = test_X.shape\n",
    "        test_X = test_X.reshape((nsamples,nx*ny))\n",
    "                        \n",
    "        '''\n",
    "        dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "        dataset.columns = ['X','y']\n",
    "        dataset.dropna(inplace=True)\n",
    "        '''\n",
    "                        \n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        model.fit(train_X,train_y)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X).reshape(-1, 1) \n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        \n",
    "        #print('y_test:',len(y_test))\n",
    "        #print('previsoes:',len(previsoes))\n",
    "               \n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),\n",
    "                              myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        \n",
    "        #Random Forest\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        model.fit(train_X,train_y)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X).reshape(-1, 1)\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged),\n",
    "                              myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        #MLP\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = 10, activation = 'relu', input_dim = train_X.shape[1]))\n",
    "        model.add(Dense(units = 21, activation = 'relu'))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X,train_y, validation_data = (train_X,train_y),  batch_size = 32, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes))  \n",
    "\n",
    "        df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged),np.mean(media_previsoes),lags)\n",
    "\n",
    "        \n",
    "        #LSTM\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 10, input_shape = (train_X_lstm.shape[1], 1)))\n",
    "        model.add(Dense(21, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X_lstm,train_y_lstm,validation_data = (train_X_lstm,train_y_lstm), batch_size = 32, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X_lstm)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test[:len(previsoes)], previsoes))\n",
    "\n",
    "        df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged),np.mean(media_previsoes),lags)\n",
    "\n",
    "        \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/temporal_pad_lag.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espaço-temporal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>179</td>\n",
       "      <td>26.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>179</td>\n",
       "      <td>29.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>179</td>\n",
       "      <td>31.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>179</td>\n",
       "      <td>32.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>179</td>\n",
       "      <td>25.84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>179</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tecnica                   parametro amostras   mape lag\n",
       "0    Regressão Linear  Coliformes Termotolerantes      179  26.49   1\n",
       "1       Random Forest  Coliformes Termotolerantes      179  29.12   1\n",
       "2                 MLP  Coliformes Termotolerantes      179  31.81   1\n",
       "3                LSTM  Coliformes Termotolerantes      179  32.22   1\n",
       "4    Regressão Linear  Coliformes Termotolerantes      179  25.84   2\n",
       "..                ...                         ...      ...    ...  ..\n",
       "315              LSTM                          pH      179   0.86   9\n",
       "316  Regressão Linear                          pH      179   0.90  10\n",
       "317     Random Forest                          pH      179   0.87  10\n",
       "318               MLP                          pH      179   0.86  10\n",
       "319              LSTM                          pH      179   0.87  10\n",
       "\n",
       "[320 rows x 5 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espaço-temporal\n",
    "print('predição espaço-temporal')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    if (len(DFmerged1) > len(DFmerged2)):\n",
    "        DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    else:\n",
    "        DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    \n",
    "    DFmerged1 = DFmerged1.interpolate(method = 'pad')\n",
    "    DFmerged2 = DFmerged2.interpolate(method = 'pad')\n",
    "    \n",
    "    DFmerged1[parameter] = tranformacao_log(DFmerged1[parameter])\n",
    "    DFmerged2[parameter] = tranformacao_log(DFmerged2[parameter])\n",
    "        \n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "    #seleciona os dados\n",
    "    \n",
    "    train1,train_previsao1, test1 = pegar_dados_coluna_predita_train_test(DFmerged1,0.70,0)\n",
    "    y_test1 = test1\n",
    "    \n",
    "    train2,train_previsao2, test2 = pegar_dados_coluna_predita_train_test(DFmerged2,0.70,0)\n",
    "    y_test2 = test2\n",
    "        \n",
    "    for lags in range(1,11):\n",
    "        \n",
    "        #normalização dos dados\n",
    "        scaler = MinMaxScaler()\n",
    "        train1,test1,testd1 = normalizacao(train1,test1)\n",
    "        train1,test1,testd1 = normalizacao(train2,test2)\n",
    "                \n",
    "        #Prepara os dados de treinamento\n",
    "        train_X1,train_y1 = prepara_dados(train1, lags,0)  \n",
    "        train_X_lstm1 = train_X1\n",
    "        train_y_lstm1 = train_y1\n",
    "        \n",
    "        train_X2,train_y2 = prepara_dados(train2, lags,0)  \n",
    "        train_X_lstm2 = train_X2\n",
    "        train_y_lstm2 = train_y2\n",
    "                \n",
    "        #Ajusta a dimensão de train_X \n",
    "        nsamples, nx, ny = train_X1.shape\n",
    "        train_X1 = train_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = train_X2.shape\n",
    "        train_X2 = train_X2.reshape((nsamples,nx*ny))\n",
    "    \n",
    "        #Prepara os dados de teste\n",
    "        entradas1 = DFmerged1[len(DFmerged1) - len(test1) - lags:].values\n",
    "        entradas1 = scaler.fit_transform(entradas1)  \n",
    "    \n",
    "        test_X1 = []\n",
    "        for i in range(lags, lags+len(test1)):        \n",
    "            test_X1.append(entradas1[i-lags:i, 0:1])\n",
    "        test_X1 = np.array(test_X1)\n",
    "        \n",
    "        test_X_lstm1 = test_X1\n",
    "        \n",
    "        entradas2 = DFmerged2[len(DFmerged2) - len(test2) - lags:].values\n",
    "        entradas2 = scaler.fit_transform(entradas2)  \n",
    "    \n",
    "        test_X2 = []\n",
    "        for i in range(lags, lags+len(test2)):        \n",
    "            test_X2.append(entradas2[i-lags:i, 0:1])\n",
    "        test_X2 = np.array(test_X2)\n",
    "        \n",
    "        test_X_lstm2 = test_X2\n",
    "                \n",
    "        #Ajusta a dimensão de test_X e train_X\n",
    "        nsamples, nx, ny = test_X1.shape\n",
    "        test_X1 = test_X1.reshape((nsamples,nx*ny))\n",
    "        \n",
    "        nsamples, nx, ny = test_X2.shape\n",
    "        test_X2 = test_X2.reshape((nsamples,nx*ny))\n",
    "                        \n",
    "        '''\n",
    "        dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "        dataset.columns = ['X','y']\n",
    "        dataset.dropna(inplace=True)\n",
    "        '''\n",
    "                        \n",
    "        #Regressão Linear\n",
    "        model = LinearRegression(normalize=False)\n",
    "\n",
    "        model.fit(train_X1,train_y1)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X2).reshape(-1, 1) \n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        \n",
    "        #print('y_test:',len(y_test))\n",
    "        #print('previsoes:',len(previsoes))\n",
    "               \n",
    "        df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),\n",
    "                              myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        \n",
    "        #Random Forest\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        model.fit(train_X1,train_y1)\n",
    "        \n",
    "        #Dados de teste\n",
    "        previsoes = model.predict(test_X2).reshape(-1, 1)\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged),\n",
    "                              myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes),lags)\n",
    "        \n",
    "        #MLP\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = 10, activation = 'relu', input_dim = train_X1.shape[1]))\n",
    "        model.add(Dense(units = 21, activation = 'relu'))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X1,train_y1, validation_data = (train_X2,train_y2),  batch_size = 32, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X2)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes))  \n",
    "\n",
    "        df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged),np.mean(media_previsoes),lags)\n",
    "\n",
    "        \n",
    "        #LSTM\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = 10, input_shape = (train_X_lstm1.shape[1], 1)))\n",
    "        model.add(Dense(21, activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "        #Treina o modelo\n",
    "        history = model.fit(train_X_lstm1,train_y_lstm1,validation_data = (train_X_lstm2,train_y_lstm2), batch_size = 32, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "        #Dados de teste\n",
    "        media_previsoes = []\n",
    "        for r in range(0,6):\n",
    "            previsoes = model.predict(test_X_lstm2)\n",
    "            previsoes = scaler.inverse_transform(previsoes)\n",
    "            media_previsoes.append(myutils.mean_absolute_percentage_error(y_test2[:len(previsoes)], previsoes))\n",
    "\n",
    "        df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged),np.mean(media_previsoes),lags)\n",
    "\n",
    "        \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/espaco_temporal_pad_lag.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predição espacial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnica</th>\n",
       "      <th>parametro</th>\n",
       "      <th>amostras</th>\n",
       "      <th>mape</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>23.96</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>29.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>30.62</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Coliformes Termotolerantes</td>\n",
       "      <td>151</td>\n",
       "      <td>29.55</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>17.81</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>18.80</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>20.26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Oxigênio Dissolvido</td>\n",
       "      <td>186</td>\n",
       "      <td>19.95</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>37.62</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>38.67</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>38.46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Turbidez</td>\n",
       "      <td>176</td>\n",
       "      <td>38.22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.78</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.49</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Fósforo Total</td>\n",
       "      <td>192</td>\n",
       "      <td>16.63</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>11.09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>2.57</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>12.99</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Sólido Total</td>\n",
       "      <td>197</td>\n",
       "      <td>12.88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>7.24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>7.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>0.53</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>DBO (5, 20)</td>\n",
       "      <td>161</td>\n",
       "      <td>0.97</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>2.68</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>3.16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>2.33</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Temperatura da Água</td>\n",
       "      <td>195</td>\n",
       "      <td>2.47</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>1.18</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MLP</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>pH</td>\n",
       "      <td>167</td>\n",
       "      <td>0.89</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tecnica                   parametro amostras   mape lag\n",
       "0   Regressão Linear  Coliformes Termotolerantes      151  23.96    \n",
       "1      Random Forest  Coliformes Termotolerantes      151  29.00    \n",
       "2                MLP  Coliformes Termotolerantes      151  30.62    \n",
       "3               LSTM  Coliformes Termotolerantes      151  29.55    \n",
       "4   Regressão Linear         Oxigênio Dissolvido      186  17.81    \n",
       "5      Random Forest         Oxigênio Dissolvido      186  18.80    \n",
       "6                MLP         Oxigênio Dissolvido      186  20.26    \n",
       "7               LSTM         Oxigênio Dissolvido      186  19.95    \n",
       "8   Regressão Linear                    Turbidez      176  37.62    \n",
       "9      Random Forest                    Turbidez      176  38.67    \n",
       "10               MLP                    Turbidez      176  38.46    \n",
       "11              LSTM                    Turbidez      176  38.22    \n",
       "12  Regressão Linear               Fósforo Total      192  16.78    \n",
       "13     Random Forest               Fósforo Total      192  16.49    \n",
       "14               MLP               Fósforo Total      192  16.25    \n",
       "15              LSTM               Fósforo Total      192  16.63    \n",
       "16  Regressão Linear                Sólido Total      197  11.09    \n",
       "17     Random Forest                Sólido Total      197   2.57    \n",
       "18               MLP                Sólido Total      197  12.99    \n",
       "19              LSTM                Sólido Total      197  12.88    \n",
       "20  Regressão Linear                 DBO (5, 20)      161   7.24    \n",
       "21     Random Forest                 DBO (5, 20)      161   7.25    \n",
       "22               MLP                 DBO (5, 20)      161   0.53    \n",
       "23              LSTM                 DBO (5, 20)      161   0.97    \n",
       "24  Regressão Linear         Temperatura da Água      195   2.68    \n",
       "25     Random Forest         Temperatura da Água      195   3.16    \n",
       "26               MLP         Temperatura da Água      195   2.33    \n",
       "27              LSTM         Temperatura da Água      195   2.47    \n",
       "28  Regressão Linear                          pH      167   1.00    \n",
       "29     Random Forest                          pH      167   1.18    \n",
       "30               MLP                          pH      167   0.88    \n",
       "31              LSTM                          pH      167   0.89    "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição espacial\n",
    "print('predição espacial')\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    \n",
    "    DFmerged1 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "    \n",
    "    DFmerged2 = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02090') &\n",
    "                      (DFmerge['parametro'] == parameter)]\n",
    "\n",
    "    \n",
    "    \n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged1 = DFmerged1[DFmerged1['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged1 = clean_group_data(DFmerged1, 'valor')\n",
    "    \n",
    "    #DFmerged2 = DFmerged2[DFmerged2['codigo_ponto'] == 'TIET02090']    \n",
    "    DFmerged2 = clean_group_data(DFmerged2, 'valor')\n",
    "    \n",
    "     \n",
    "    \n",
    "    DFmerged1['data_coleta'] = pd.to_datetime(DFmerged1['data_coleta'])\n",
    "    DFmerged1.index = DFmerged1['data_coleta']    \n",
    "    DFmerged1 = DFmerged1.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged1 = DFmerged1.loc['1979-01-31':]\n",
    "       \n",
    "    DFmerged2['data_coleta'] = pd.to_datetime(DFmerged2['data_coleta'])\n",
    "    DFmerged2.index = DFmerged2['data_coleta']    \n",
    "    DFmerged2 = DFmerged2.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged2 = DFmerged2.loc['1979-01-31':]\n",
    "    \n",
    "    #coloca o dataframes com o mesmo tamanho\n",
    "    #DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    if (len(DFmerged1) > len(DFmerged2)):\n",
    "        DFmerged1 = DFmerged1.iloc[0:len(DFmerged2)]\n",
    "    else:\n",
    "        DFmerged2 = DFmerged2.iloc[0:len(DFmerged1)]   \n",
    "    \n",
    "    DFmerged1 = DFmerged1.interpolate(method = 'pad')\n",
    "    DFmerged2 = DFmerged2.interpolate(method = 'pad')\n",
    "    \n",
    "    DFmerged1[parameter] = tranformacao_log(DFmerged1[parameter])\n",
    "    DFmerged2[parameter] = tranformacao_log(DFmerged2[parameter])\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    #DFmerged = scaler.fit_transform(np.log(DFmerged + 0.0000001))\n",
    "#     DFmerged = scaler.fit_transform()\n",
    "\n",
    "    # #Mostra a quantidade de NaN no dataframe\n",
    "    #for field in DFmerge.columns:\n",
    "        #print(field, 'NaN:', DFmerge[field].isnull().sum())\n",
    "    #print(parameter)    \n",
    "    #print('Valor', 'NaN:', DFmerge['valor'].isnull().sum())\n",
    "    \n",
    "        \n",
    "    X  = DFmerged1[:]\n",
    "    y  = DFmerged2[:]\n",
    "\n",
    "\n",
    "    dataset = pd.DataFrame(np.concatenate([X,y], axis=1))\n",
    "    dataset.columns = ['X','y']\n",
    "    dataset.dropna(inplace=True)\n",
    "\n",
    "    #train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "    #train_y = scaler.fit_transform(np.log(np.array(dataset['y']).reshape(len(dataset), 1) + 0.000000001))\n",
    "    \n",
    "    train_X = scaler.fit_transform(np.array(dataset['X']).reshape(len(dataset), 1))\n",
    "    train_y = scaler.fit_transform(np.array(dataset['y']).reshape(len(dataset), 1))\n",
    "        \n",
    "    #tamanho_treino = int(len(train_X)*0.7)\n",
    "    tamanho_teste  = int(len(train_y)*0.3)\n",
    "\n",
    "    #Desnormalização train_y(teste)\n",
    "    y_teste = scaler.inverse_transform(train_y[-tamanho_teste:])\n",
    "\n",
    "    #Regressão Linear\n",
    "    model = LinearRegression(normalize=False)\n",
    "\n",
    "    #model.fit(train_X[:-40],train_y[:-40])\n",
    "    model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "    score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "    #Dados de teste\n",
    "    #previsoes = model.predict(train_X[-40:])\n",
    "    previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "    previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "    #df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged),myutils.mean_absolute_percentage_error(train_y[-40:], previsoes))\n",
    "    df_result = resultado(df_resultado,'Regressão Linear',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),'')\n",
    "        \n",
    "        \n",
    "    #print(parameter, len(DFmerged),'MAPE',str(myutils.mean_absolute_percentage_error(train_y[-40:], previsoes)))\n",
    "\n",
    "    #Random Forest\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste])\n",
    "    score = model.score(train_X,train_y)\n",
    "    #     print(score)\n",
    "\n",
    "    #Dados de teste\n",
    "    previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "    previsoes = scaler.inverse_transform(previsoes.reshape(-1, 1))\n",
    "\n",
    "    df_result = resultado(df_resultado,'Random Forest',parameter,len(DFmerged1),\n",
    "                              myutils.mean_absolute_percentage_error(y_teste, previsoes),'')\n",
    "\n",
    "    #MLP\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, activation = 'relu', input_dim = train_X[:-tamanho_teste].shape[1]))\n",
    "    model.add(Dense(units = 21, activation = 'relu'))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste], validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]),  batch_size = 32, epochs = 2000, callbacks=[es], verbose=0)\n",
    "\n",
    "    #Dados de teste\n",
    "    media_previsoes = []\n",
    "    for r in range(0,6):\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "\n",
    "        media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))  \n",
    "\n",
    "    df_result = resultado(df_resultado,'MLP',parameter,len(DFmerged1),np.mean(media_previsoes),'')\n",
    "\n",
    "\n",
    "    #LSTM\n",
    "\n",
    "    train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "    train_y = np.reshape(train_y, (train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 10, input_shape = (train_X[:-tamanho_teste].shape[1], 1)))\n",
    "    model.add(Dense(21, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mean_absolute_error', optimizer = 'adam',metrics = ['mean_absolute_error'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience = 5, verbose=0)\n",
    "\n",
    "    #Treina o modelo\n",
    "    history = model.fit(train_X[:-tamanho_teste],train_y[:-tamanho_teste],validation_data = (train_X[:-tamanho_teste],train_y[:-tamanho_teste]), batch_size = 32, epochs = 100, callbacks=[es], verbose=0)\n",
    "\n",
    "    #Dados de teste\n",
    "    media_previsoes = []\n",
    "    for r in range(0,6):\n",
    "        previsoes = model.predict(train_X[-tamanho_teste:])\n",
    "        previsoes = scaler.inverse_transform(previsoes)\n",
    "        media_previsoes.append(myutils.mean_absolute_percentage_error(y_teste, previsoes))\n",
    "\n",
    "    df_result = resultado(df_resultado,'LSTM',parameter,len(DFmerged1),np.mean(media_previsoes),'')\n",
    "\n",
    "         \n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv (r'/home/anderson/Downloads/predicaoagua/src/espacial_pad.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8245492922123363,\n",
       " 1.8137383761098738,\n",
       " 1.7917594693947216,\n",
       " 1.8908503720232293,\n",
       " 1.8405496335562173,\n",
       " 1.8562979905218762,\n",
       " 1.8245492922123363,\n",
       " 1.8245492922123363,\n",
       " 1.8614928073981707,\n",
       " 1.8562979905218762,\n",
       " 1.8718021770554376,\n",
       " 1.8562979905218762,\n",
       " 1.8137383761098738,\n",
       " 1.8082887713431999,\n",
       " 1.8562979905218762,\n",
       " 1.8245492922123363,\n",
       " 1.8562979905218762,\n",
       " 1.8082887713432,\n",
       " 1.8405496335562173,\n",
       " 1.8718021770554376,\n",
       " 1.9315214117481414,\n",
       " 1.8718021770554376,\n",
       " 1.9169226123291199,\n",
       " 1.8484548130620806,\n",
       " 1.9021075265461742,\n",
       " 1.8245492922123363,\n",
       " 1.8562979905218762,\n",
       " 1.9242486524201192,\n",
       " 1.9021075265461742,\n",
       " 1.8718021770554376,\n",
       " 1.8405496335562173,\n",
       " 1.8082887713431999,\n",
       " 1.887069649183895,\n",
       " 1.8405496335562173,\n",
       " 1.8405496335562173,\n",
       " 1.8245492922123363,\n",
       " 1.8562979905218762,\n",
       " 1.8082887713431999,\n",
       " 1.7917594693947216,\n",
       " 1.8405496335562173,\n",
       " 1.8718021770554376,\n",
       " 1.8325814639083102,\n",
       " 1.8082887713431999,\n",
       " 1.8245492922123363,\n",
       " 1.8245492922123363,\n",
       " 1.9021075265461742,\n",
       " 1.8245492922123363,\n",
       " 1.8245492922123363,\n",
       " 1.8562979905218762,\n",
       " 1.8405496335562173,\n",
       " 1.8245492922123363,\n",
       " 1.7917594693947216,\n",
       " 1.9169226123291199,\n",
       " 1.8718021770554376,\n",
       " 1.8562979905218762,\n",
       " 1.8405496335562173,\n",
       " 1.9315214117481414,\n",
       " 1.8405496335562173,\n",
       " 1.8405496335562173,\n",
       " 1.9315214117481414,\n",
       " 1.8794650497998324,\n",
       " 1.8562979905218762,\n",
       " 1.8562979905218762,\n",
       " 1.8405496335562173,\n",
       " 1.9169226123291199,\n",
       " 1.8082887713431999,\n",
       " 1.8245492922123363,\n",
       " 1.8405496335562173,\n",
       " 1.8082887713431999,\n",
       " 1.9459101491981705,\n",
       " 1.8562979905218762,\n",
       " 1.8245492922123363,\n",
       " 1.9315214117481414,\n",
       " 1.8718021770554376,\n",
       " 1.9021075265461742,\n",
       " 1.8718021770554376,\n",
       " 1.8562979905218762,\n",
       " 1.8718021770554376,\n",
       " 1.8946168548181388,\n",
       " 1.8718021770554376,\n",
       " 1.9021075265461742,\n",
       " 1.9095425050325867,\n",
       " 1.9315214117481414,\n",
       " 1.8245492922123363,\n",
       " 1.9021075265461742,\n",
       " 1.8718021770554376,\n",
       " 1.8562979905218762,\n",
       " 1.8562979905218762,\n",
       " 1.7917594693947216,\n",
       " 1.9315214117481414,\n",
       " 1.9169226123291199,\n",
       " 1.8164520819810281,\n",
       " 1.8245492922123363,\n",
       " 1.8405496335562173,\n",
       " 1.9021075265461742,\n",
       " 1.8718021770554376,\n",
       " 1.8405496335562173,\n",
       " 1.8245492922123363,\n",
       " 1.8245492922123363,\n",
       " 1.8718021770554376,\n",
       " 1.887069649183895,\n",
       " 1.9169226123291199,\n",
       " 1.9169226123291199,\n",
       " 1.887069649183895,\n",
       " 1.9169226123291199,\n",
       " 1.887069649183895,\n",
       " 1.8245492922123363,\n",
       " 1.887069649183895,\n",
       " 1.7917594693947216,\n",
       " 1.8082887713431999,\n",
       " 1.9169226123291199,\n",
       " 1.887069649183895,\n",
       " 1.8562979905218762,\n",
       " 1.8718021770554376,\n",
       " 1.8562979905218762,\n",
       " 1.8245492922123363,\n",
       " 1.8245492922123363,\n",
       " 1.8082887713431999,\n",
       " 1.8718021770554376,\n",
       " 1.8718021770554376,\n",
       " 1.8245492922123363,\n",
       " 1.8405496335562173,\n",
       " 1.8794650497998322,\n",
       " 1.887069649183895,\n",
       " 1.8562979905218762,\n",
       " 1.9021075265461742,\n",
       " 1.8562979905218762,\n",
       " 1.8082887713431999,\n",
       " 1.8405496335562173,\n",
       " 1.9021075265461742,\n",
       " 1.8405496335562173,\n",
       " 1.8562979905218762,\n",
       " 1.8405496335562173,\n",
       " 1.8405496335562173,\n",
       " 1.8405496335562173,\n",
       " 1.8405496335562173,\n",
       " 1.887069649183895,\n",
       " 1.8718021770554376,\n",
       " 1.8405496335562173,\n",
       " 1.8245492922123363,\n",
       " 1.8405496335562173,\n",
       " 1.8405496335562173,\n",
       " 1.9021075265461742,\n",
       " 1.8562979905218762,\n",
       " 1.8245492922123363,\n",
       " 1.8405496335562173,\n",
       " 1.8718021770554376,\n",
       " 1.8405496335562173,\n",
       " 1.887069649183895,\n",
       " 1.8453002363140627,\n",
       " 1.8961194847024478,\n",
       " 1.862528540271542,\n",
       " 1.8764069434414792,\n",
       " 1.9198594720019984,\n",
       " 1.9050881546838676,\n",
       " 1.9430489169175476,\n",
       " 1.8180767777077662,\n",
       " 1.9257074418835665,\n",
       " 1.9139771020997969,\n",
       " 1.9213246737291116,\n",
       " 1.860974538405049,\n",
       " 1.8900953700999743,\n",
       " 1.8515994697410578,\n",
       " 1.8771723472292074,\n",
       " 1.8825138326487263,\n",
       " 1.8341801852717516,\n",
       " 1.8468787686068633,\n",
       " 1.8050046961425494,\n",
       " 1.8468787686068633,\n",
       " 1.8293763329598756,\n",
       " 1.8946168548181388,\n",
       " 1.8547342685459378,\n",
       " 1.843719208316994,\n",
       " 1.9169226123291199,\n",
       " 1.8515994697410578,\n",
       " 1.9213246737291116,\n",
       " 1.8099267733471702,\n",
       " 1.8633046365463097,\n",
       " 1.8325814639083102]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tranformacao_log(valores_parametro):\n",
    "   \n",
    "    valores_log = []\n",
    "   \n",
    "    for i in range(len(valores_parametro)):\n",
    "        #print(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "        valores_log.append(np.log(np.array(valores_parametro[i]) + 0.000000001))\n",
    "       \n",
    "    return valores_log\n",
    "\n",
    "parameters = ['coliformes', 'od', 'turbidez', 'fosforo', 'solido', 'dbo', 'temperatura', 'ph']\n",
    "df_resultado = pd.DataFrame(columns=['tecnica','parametro','amostras','mape','lag'])\n",
    "\n",
    "DFmerge = pd.DataFrame()\n",
    "for parameter in parameters:\n",
    "    # Concatenating all the parameter files\n",
    "    df = pd.read_csv('../data/CETESB/'+ parameter + '.csv',encoding='utf-8',sep=';')\n",
    "    DFmerge = pd.concat([DFmerge, df])\n",
    "    \n",
    "    \n",
    "for parameter in DFmerge['parametro'].unique():    \n",
    "    DFmerged = DFmerge[(DFmerge['codigo_ponto'] == 'TIET02050') &\n",
    "                      (DFmerge['parametro'] == parameter)]  \n",
    "\n",
    "    \n",
    "\n",
    "    # DFmerge.groupby([pd.Grouper(freq='1M'), 'codigo_ponto']).mean().unstack()\n",
    "    # DFmerge.groupby(['codigo_ponto', 'UGRHI'])['valor'].count().unstack()\n",
    "\n",
    "    #DFmerged = DFmerged[DFmerged['codigo_ponto'] == 'TIET02050']    \n",
    "    DFmerged = clean_group_data(DFmerged, 'valor')\n",
    "    \n",
    "    DFmerged['data_coleta'] = pd.to_datetime(DFmerged['data_coleta'])\n",
    "    DFmerged.index = DFmerged['data_coleta']    \n",
    "    DFmerged = DFmerged.groupby([pd.Grouper(freq='1M'), 'parametro'])['valor'].mean().unstack()\n",
    "    DFmerged = DFmerged.loc['1979-01-31':]\n",
    "    \n",
    "    DFmerged.interpolate(method = 'pad')\n",
    "    \n",
    "      \n",
    "    scaler = MinMaxScaler()\n",
    "    DFmerged = tranformacao_log(DFmerged[parameter])\n",
    "DFmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
