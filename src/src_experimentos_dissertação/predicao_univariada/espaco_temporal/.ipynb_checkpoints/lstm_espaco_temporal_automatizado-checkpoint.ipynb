{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_files = ''\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi06 = pd.read_csv(str_files + \"cetesb_concatenado06semoutliers.csv\",encoding='utf-8',sep=',',index_col=[0])\n",
    "\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi10 = pd.read_csv(str_files + \"cetesb_concatenado10semoutliers.csv\",encoding='utf-8',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Tamanho dos conjuntos originais ----\n",
      "ugrhi06: 503\n",
      "ugrhi10: 502\n",
      "---- Conjunto de dados y igualado ao tamanho de dados do conjunto X ----\n",
      "ugrhi06: 502\n",
      "ugrhi10: 502\n"
     ]
    }
   ],
   "source": [
    "print('---- Tamanho dos conjuntos originais ----')\n",
    "print('ugrhi06:',len(df_ugrhi06))\n",
    "print('ugrhi10:',len(df_ugrhi10))\n",
    "\n",
    "#Seleciona os dados equivalente ao tamanho da URGHI10\n",
    "df_ugrhi06 = df_ugrhi06.iloc[0:len(df_ugrhi10)]\n",
    "\n",
    "#Seleciona os valores da coluna ph da URGHI06, na qual será utilizado para a normalização dos dados quando apresentar o gráfico\n",
    "#train_previsao = ugrhi06['ph'].values\n",
    "#train_previsao = train_previsao.reshape(len(train_previsao),1)\n",
    "\n",
    "print('---- Conjunto de dados y igualado ao tamanho de dados do conjunto X ----')\n",
    "print('ugrhi06:',len(df_ugrhi06))\n",
    "print('ugrhi10:',len(df_ugrhi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_colunas(trainingd,ug):\n",
    "    \n",
    "    if (ug == 6):        \n",
    "        fph      = trainingd.iloc[:,0:1].values\n",
    "        \n",
    "        frame_completo = pd.DataFrame(list(zip(fph)),columns =['ph']) \n",
    "    else:\n",
    "        fph      = trainingd.iloc[:,1:2].values\n",
    "            \n",
    "        frame_completo = pd.DataFrame(list(zip(fph)),columns =['ph'])\n",
    "        \n",
    "    \n",
    "    return frame_completo\n",
    "\n",
    "def seleciona_colunas_od(trainingd,ug):\n",
    "    \n",
    "    if (ug == 6):\n",
    "        \n",
    "        fod      = trainingd.iloc[:,4:5].values\n",
    "        \n",
    "        frame_completo = pd.DataFrame(list(zip(fod)),columns =['od']) \n",
    "    else:\n",
    "        fod      = trainingd.iloc[:,5:6].values\n",
    "            \n",
    "        frame_completo = pd.DataFrame(list(zip(fod)),columns =['od'])\n",
    "        \n",
    "    \n",
    "    return frame_completo  \n",
    "\n",
    "def pega_index_coluna_ugrhi10(p):\n",
    "    \n",
    "    index_coluna = 0\n",
    "    \n",
    "    if (p == 'solido'):\n",
    "        index_coluna = 0\n",
    "    elif (p == 'ph'):\n",
    "        index_coluna = 1\n",
    "    elif (p == 'coliformes'):\n",
    "        index_coluna = 2 \n",
    "    elif (p == 'dbo'):\n",
    "        index_coluna = 3\n",
    "    elif (p == 'fosforo'):\n",
    "        index_coluna == 4\n",
    "    elif (p == 'od'):\n",
    "        index_coluna = 5 \n",
    "    elif (p == 'temperatura'):\n",
    "        index_coluna = 6 \n",
    "    elif (p == 'turbidez'):\n",
    "        index_coluna = 7\n",
    "        \n",
    "    return index_coluna\n",
    "\n",
    "def seleciona_colunas_p(trainingd,p,index_coluna):\n",
    "    fp      = trainingd.iloc[:,index_coluna:index_coluna+1].values\n",
    "        \n",
    "    frame_completo = pd.DataFrame(list(zip(fp)),columns =[p]) \n",
    "    \n",
    "    return frame_completo\n",
    "\n",
    "def pegar_dados_coluna_predita_train_test(trainingd,percent,index_coluna):\n",
    "    data = trainingd.iloc[:,:].values\n",
    "    train = trainingd.iloc[0:int(len(data)*percent),:].values  \n",
    "    train_previsao = trainingd.iloc[0:int(len(data)*percent),index_coluna:index_coluna+1].values\n",
    "    test = trainingd.iloc[len(train):,index_coluna:index_coluna+1].values\n",
    "    \n",
    "    return train,train_previsao, test\n",
    "\n",
    "#Normalização dos dados: Normaliza os dados dentro um intervalo (0 a 1).\n",
    "def normalizacao(train,test):\n",
    "    sc = MinMaxScaler()\n",
    "    testd = test\n",
    "    train = sc.fit_transform(train)\n",
    "    test = sc.fit_transform(test)    \n",
    "    return train,test,testd\n",
    "\n",
    "#Prepara o conjunto de dados em X e y, considerando a janela de visualização (lags).\n",
    "#cy = coluna que será predita\n",
    "def prepara_dados(dados,lags,cy):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(lags, len(dados)):\n",
    "        X.append(dados[i-lags:i,:])\n",
    "        y.append(dados[i, cy])\n",
    "       \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#Calcula o MAPE\n",
    "#Define função para calcular o MAPE\n",
    "#def mape(y_pred,y_true):\n",
    " #   return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mape(y_pred,y_true):\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    '''  \n",
    "    mape_sum = 0\n",
    "    for real,prediction in zip(y_true,y_pred):\n",
    "        mape_sum += (abs((real - prediction))/real)\n",
    "        \n",
    "        print(real)\n",
    "        mape = mape_sum/len(real)\n",
    "    '''\n",
    "    return mape\n",
    "\n",
    "def rmse(y_pred,y_true):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def r2(y_pred,y_true):\n",
    "    rscore = r2_score(y_true,y_pred)\n",
    "    return rscore\n",
    "\n",
    "def rquadrado(y_pred,y_true):\n",
    "    #Soma Total dos Quadrados (STQ): mostra a variação de y em torno da própria média. \n",
    "    #É o somatório das diferenças entre o valor alvo real e sua média elevado ao quadrado.\n",
    "    y_traco = np.mean(y_true)\n",
    "    \n",
    "    print('media y_true:', y_traco)\n",
    "        \n",
    "    stq = 0\n",
    "    \n",
    "    for s in y_true:\n",
    "        a = s - y_traco\n",
    "        st = a * a\n",
    "        stq = stq + st\n",
    "    \n",
    "    print('Soma Total dos Quadrados (STQ):', stq[0])\n",
    "    \n",
    "    #Soma dos Quadrados dos Resíduos (SQU): variação de Y que não é explicada pelo modelo elaborado. \n",
    "    #É o somatório das diferenças entre o valor predito e o valor real elevados ao quadrado.\n",
    "    squ = 0\n",
    "    \n",
    "    y_traco = np.mean(y_pred)\n",
    "    print('media y_pred:', y_traco)\n",
    "    \n",
    "    for n in range(len(y_true)):\n",
    "        a = y_true[n] - y_pred[n]\n",
    "        st = a * a\n",
    "        squ = squ + st\n",
    "        \n",
    "    print('Soma dos Quadrados dos Resíduos (SQU):',squ[0])\n",
    "    print('\\n')\n",
    "    print('Fórmula do R²')\n",
    "    print('\\n')\n",
    "    print('sqr = stq - squ')\n",
    "    sqr = stq[0] - squ[0]\n",
    "    print('R² = sqr/stq')\n",
    "    sqr = sqr/stq[0]\n",
    "    print('\\n')\n",
    "    return sqr\n",
    "\n",
    "def correlacao_determinacao(dtframe,tipo):\n",
    "    \n",
    "    if (tipo == 0): #Treino\n",
    "        resultado = dtframe.corr().previsao_treino.values[1]**2\n",
    "    else: #teste\n",
    "        resultado = dtframe.corr().previsao_teste.values[1]**2\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "def ajusta_array(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def ajusta_lista(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ph\n",
      "0    [6.415254237288135]\n",
      "1    [6.404951629130872]\n",
      "2    [6.393545170099616]\n",
      "3    [6.382506661359692]\n",
      "4    [6.371100202328434]\n",
      "..                   ...\n",
      "497               [7.56]\n",
      "498               [7.34]\n",
      "499               [7.37]\n",
      "500  [6.827000000000001]\n",
      "501               [6.92]\n",
      "\n",
      "[502 rows x 1 columns]\n",
      "                       ph\n",
      "0     [7.094057396342201]\n",
      "1     [7.105960703508023]\n",
      "2     [7.105960703508023]\n",
      "3     [7.120679481845853]\n",
      "4     [7.120679481845853]\n",
      "..                    ...\n",
      "497   [7.136286635823778]\n",
      "498   [7.136286635823778]\n",
      "499  [7.2068979591836735]\n",
      "500  [7.1346530612244905]\n",
      "501  [7.0600000000000005]\n",
      "\n",
      "[502 rows x 1 columns]\n",
      "Epoch 00008: early stopping\n",
      "Teste - Gráficos com lag 1\n",
      "Treinamento - Gráficos com lag 1\n",
      "Epoch 00012: early stopping\n",
      "Teste - Gráficos com lag 2\n",
      "Treinamento - Gráficos com lag 2\n",
      "Epoch 00012: early stopping\n",
      "Teste - Gráficos com lag 3\n",
      "Treinamento - Gráficos com lag 3\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 4\n",
      "Treinamento - Gráficos com lag 4\n",
      "Epoch 00007: early stopping\n",
      "Teste - Gráficos com lag 5\n",
      "Treinamento - Gráficos com lag 5\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 6\n",
      "Treinamento - Gráficos com lag 6\n",
      "Epoch 00006: early stopping\n",
      "Teste - Gráficos com lag 7\n",
      "Treinamento - Gráficos com lag 7\n",
      "Epoch 00007: early stopping\n",
      "Teste - Gráficos com lag 8\n",
      "Treinamento - Gráficos com lag 8\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 9\n",
      "Treinamento - Gráficos com lag 9\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 10\n",
      "Treinamento - Gráficos com lag 10\n",
      "Epoch 00007: early stopping\n",
      "Teste - Gráficos com lag 11\n",
      "Treinamento - Gráficos com lag 11\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 12\n",
      "Treinamento - Gráficos com lag 12\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 13\n",
      "Treinamento - Gráficos com lag 13\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 14\n",
      "Treinamento - Gráficos com lag 14\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 15\n",
      "Treinamento - Gráficos com lag 15\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 16\n",
      "Treinamento - Gráficos com lag 16\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 17\n",
      "Treinamento - Gráficos com lag 17\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 18\n",
      "Treinamento - Gráficos com lag 18\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 19\n",
      "Treinamento - Gráficos com lag 19\n",
      "Epoch 00008: early stopping\n",
      "Teste - Gráficos com lag 20\n",
      "Treinamento - Gráficos com lag 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags_treino</th>\n",
       "      <th>mape_treino</th>\n",
       "      <th>rmse_treino</th>\n",
       "      <th>r_quad_treino</th>\n",
       "      <th>lags_teste</th>\n",
       "      <th>mape_teste</th>\n",
       "      <th>rmse_teste</th>\n",
       "      <th>r_quad_teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.422915</td>\n",
       "      <td>0.387965</td>\n",
       "      <td>0.093855</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.456050</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.91608</td>\n",
       "      <td>0.348760</td>\n",
       "      <td>0.024653</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>5.91608</td>\n",
       "      <td>0.393846</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>0.002013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.759600</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.679900</td>\n",
       "      <td>0.336500</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.75000</td>\n",
       "      <td>5.198000</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>5.75000</td>\n",
       "      <td>5.200100</td>\n",
       "      <td>0.373075</td>\n",
       "      <td>0.004325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.404450</td>\n",
       "      <td>0.386650</td>\n",
       "      <td>0.095550</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.450450</td>\n",
       "      <td>0.390850</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.25000</td>\n",
       "      <td>5.656675</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.102625</td>\n",
       "      <td>15.25000</td>\n",
       "      <td>5.716975</td>\n",
       "      <td>0.409750</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>6.137700</td>\n",
       "      <td>0.438600</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>6.194500</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lags_treino  mape_treino  rmse_treino  r_quad_treino  lags_teste  \\\n",
       "count     20.00000    20.000000    20.000000      20.000000    20.00000   \n",
       "mean      10.50000     5.422915     0.387965       0.093855    10.50000   \n",
       "std        5.91608     0.348760     0.024653       0.013595     5.91608   \n",
       "min        1.00000     4.759600     0.341300       0.067000     1.00000   \n",
       "25%        5.75000     5.198000     0.372000       0.086800     5.75000   \n",
       "50%       10.50000     5.404450     0.386650       0.095550    10.50000   \n",
       "75%       15.25000     5.656675     0.404500       0.102625    15.25000   \n",
       "max       20.00000     6.137700     0.438600       0.125400    20.00000   \n",
       "\n",
       "       mape_teste  rmse_teste  r_quad_teste  \n",
       "count   20.000000   20.000000     20.000000  \n",
       "mean     5.456050    0.391275      0.005400  \n",
       "std      0.393846    0.027934      0.002013  \n",
       "min      4.679900    0.336500      0.002100  \n",
       "25%      5.200100    0.373075      0.004325  \n",
       "50%      5.450450    0.390850      0.005200  \n",
       "75%      5.716975    0.409750      0.006100  \n",
       "max      6.194500    0.443900      0.009800  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultado_medio_g = pd.DataFrame()\n",
    "\n",
    "index_coluna = 0\n",
    "\n",
    "parametro = []\n",
    "tecnica   = []\n",
    "\n",
    "#média\n",
    "media_parametro_mape_treino = []\n",
    "media_parametro_rmse_treino = []\n",
    "media_parametro_r_treino    = []\n",
    "    \n",
    "media_parametro_mape_teste  = []\n",
    "media_parametro_rmse_teste  = []\n",
    "media_parametro_r_teste     = []\n",
    "    \n",
    "#desvio_padrão\n",
    "    \n",
    "std_parametro_mape_treino = []\n",
    "std_parametro_rmse_treino = []\n",
    "std_parametro_r_treino    = []\n",
    "    \n",
    "std_parametro_mape_teste  = []\n",
    "std_parametro_rmse_teste  = []\n",
    "std_parametro_r_teste     = []\n",
    "\n",
    "for p in ('ph','coliformes', 'dbo','fosforo','od','solido','temperatura','turbidez'):\n",
    "    \n",
    "    print('Agora é a vez do parâmetro:', p)\n",
    "   \n",
    "    ugrhi06 = seleciona_colunas_p(df_ugrhi06,p,index_coluna)\n",
    "    ugrhi10 = seleciona_colunas_p(df_ugrhi10,p,pega_index_coluna_ugrhi10(p))\n",
    "   \n",
    "    index_coluna = index_coluna + 1\n",
    "\n",
    "    df_resultados_treino = pd.DataFrame()\n",
    "    df_resultados_teste  = pd.DataFrame()\n",
    "    df_resultados        = pd.DataFrame()\n",
    "    \n",
    "    media_lag_mape_treino = []\n",
    "    media_lag_rmse_treino = []\n",
    "    media_lag_r_treino    = []\n",
    "        \n",
    "    media_lag_mape_teste = []\n",
    "    media_lag_rmse_teste = []\n",
    "    media_lag_r_teste    = []\n",
    "    \n",
    "    for l in range(1, 16):\n",
    "    \n",
    "    lags = l\n",
    "    \n",
    "    #seleciona os dados\n",
    "    \n",
    "        train06,train_previsao06, test06 = pegar_dados_coluna_predita_train_test(ugrhi06,0.70,0) \n",
    "        train10,train_previsao10, test10 = pegar_dados_coluna_predita_train_test(ugrhi10,0.70,0) \n",
    "\n",
    "        #normalização dos dados\n",
    "        train06,test06,testd06 = normalizacao(train06,test06)\n",
    "        train10,test10,testd10 = normalizacao(train10,test10)\n",
    "\n",
    "        normalizador_previsao = MinMaxScaler()\n",
    "        sc = MinMaxScaler()\n",
    "        normalizador_previsao.fit_transform(train_previsao06)\n",
    "\n",
    "        #Prepara os dados de treinamento -ugrhi06\n",
    "        #Vai predizer o valor da coluna 4 (valor ph)\n",
    "        train_X06, train_y06 = prepara_dados(train06, lags,0)\n",
    "\n",
    "        #Prepara os dados de teste\n",
    "        entradas06 = ugrhi06[len(ugrhi06) - len(test06) - lags:].values\n",
    "        entradas06 = sc.fit_transform(entradas06)   \n",
    "\n",
    "        test_X06 = []\n",
    "        for i in range(lags, lags+len(test06)):\n",
    "            test_X06.append(entradas06[i-lags:i, 0:1])\n",
    "        test_X06 = np.array(test_X06)\n",
    "\n",
    "        #Prepara os dados de treinamento -ugrhi10\n",
    "        #Aqui vamos pegar test_X10.\n",
    "        train_X10, train_y10 = prepara_dados(train10, lags,0)\n",
    "\n",
    "        #Prepara os dados de teste\n",
    "        entradas10 = ugrhi10[len(ugrhi10) - len(test10) - lags:].values\n",
    "        entradas10 = sc.fit_transform(entradas10)   \n",
    "\n",
    "        test_X10 = []\n",
    "        for i in range(lags, lags+len(test10)):\n",
    "            test_X10.append(entradas10[i-lags:i, 0:1])\n",
    "        test_X10 = np.array(test_X10)\n",
    "        \n",
    "        media_simulador_mape_treino = []\n",
    "        media_simulador_rmse_treino = []\n",
    "        media_simulador_r_treino    = []\n",
    "\n",
    "        media_simulador_mape_teste  = []\n",
    "        media_simulador_rmse_teste  = []\n",
    "        media_simulador_r_teste     = []\n",
    "        \n",
    "        for r in range(0,6)\n",
    "    \n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units = 10, input_shape = (train_X06.shape[1], 1)))\n",
    "            model.add(Dense(21, activation = 'relu'))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(1, activation = 'sigmoid'))\n",
    "            model.compile(loss = 'mean_absolute_error', optimizer = 'adam',\n",
    "                          metrics = ['mean_absolute_error'])\n",
    "\n",
    "            es = EarlyStopping(monitor='val_loss', patience = 3, verbose=0)\n",
    "\n",
    "\n",
    "            #Treina o modelo\n",
    "            history = model.fit(train_X06, train_y06, validation_data=(test_X10, test10), batch_size = 32, epochs = 2000, \n",
    "                                callbacks=[es], verbose=0)\n",
    "\n",
    "            #Treina o modelo\n",
    "            #model.fit(train_X06, train_y06, batch_size = 32, epochs = 100)\n",
    "\n",
    "            #Dados de teste\n",
    "            previsoes = model.predict(test_X10)\n",
    "            #previsoes = previsoes.reshape(-1, 1)\n",
    "            previsoes = normalizador_previsao.inverse_transform(previsoes)\n",
    "\n",
    "            #print('Teste - Gráficos com lag', l)\n",
    "            '''\n",
    "            #Plotagem do gráfico\n",
    "            plt.plot(testd10,color='red',label = 'Observado')\n",
    "            plt.plot(previsoes,color='blue',label = 'Previsoes')\n",
    "            plt.xlabel('Tempo')\n",
    "            plt.ylabel('Valor pH')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            #Dados de treino\n",
    "            previsoes_treino = model.predict(train_X10)\n",
    "            previsoes_treino = previsoes_treino.reshape(-1, 1)\n",
    "            previsoes_treino = normalizador_previsao.inverse_transform(previsoes_treino)\n",
    "\n",
    "            treino = train_previsao10[lags: len(previsoes_treino) + lags, :]\n",
    "            observado_test = testd10\n",
    "\n",
    "            observado_treino = train_previsao10  \n",
    "\n",
    "            #print('Treinamento - Gráficos com lag', l)\n",
    "            '''\n",
    "            #Plotagem do gráfico\n",
    "            plt.plot(train_previsao10,color='red',label = 'Observado')\n",
    "            plt.plot(previsoes_treino,color='blue',label = 'Previsoes')\n",
    "            plt.xlabel('Tempo')\n",
    "            plt.ylabel('Valor pH')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            treino         = ajusta_array(treino)\n",
    "            observado_test = ajusta_array(observado_test)\n",
    "\n",
    "            #Calculo do erro da previsão MAPE, RMSE e R²\n",
    "\n",
    "            observado_treino_d = observado_treino\n",
    "            previsoes_treino_d = previsoes_treino\n",
    "            previsoes_d        = previsoes\n",
    "\n",
    "            mape_treino_d        = round(mape(previsoes_treino,treino),4)\n",
    "            rmse_treino_d        = round(rmse(previsoes_treino,treino),4)\n",
    "            #r_treino_d           = round(r2(previsoes_treino,treino),4)\n",
    "\n",
    "            mape_teste_d        = round(mape(previsoes,observado_test),4)\n",
    "            rmse_teste_d        = round(rmse(previsoes,observado_test),4)\n",
    "            #r_teste_d           = round(r2(previsoes,observado_test),4) \n",
    "\n",
    "            df_corr_determinacao_treino = pd.DataFrame()\n",
    "            df_corr_determinacao_teste  = pd.DataFrame()\n",
    "\n",
    "            #Calcula o coeficiente de determinação\n",
    "            dict = {'previsao_treino': ajusta_lista(previsoes_treino), 'treino': ajusta_array(treino)} \n",
    "\n",
    "            df_treino = pd.DataFrame(dict)\n",
    "            dframes_treino = [df_corr_determinacao_treino,df_treino]\n",
    "            df_corr_determinacao_treino = pd.concat(dframes_treino)\n",
    "\n",
    "            dict = {'previsao_teste': ajusta_lista(previsoes), 'teste': ajusta_array(observado_test)} \n",
    "\n",
    "            df_teste = pd.DataFrame(dict)\n",
    "            dframes_teste = [df_corr_determinacao_teste,df_teste]\n",
    "            df_corr_determinacao_teste = pd.concat(dframes_teste)\n",
    "\n",
    "            r_treino_d = []\n",
    "            r_teste_d  = []\n",
    "\n",
    "            r_treino_d.append(round(correlacao_determinacao(df_corr_determinacao_treino,0),4))\n",
    "            r_teste_d.append(round(correlacao_determinacao(df_corr_determinacao_teste,1),4))\n",
    "            \n",
    "            media_simulador_mape_treino.append(np.mean(mape_treino_d))\n",
    "            media_simulador_rmse_treino.append(np.mean(rmse_treino_d))\n",
    "            media_simulador_r_treino.append(np.mean(r_treino_d))\n",
    "            \n",
    "            media_simulador_mape_teste.append(np.mean(mape_teste_d))\n",
    "            media_simulador_rmse_teste.append(np.mean(rmse_teste_d))\n",
    "            media_simulador_r_teste.append(np.mean(r_teste_d))\n",
    "            \n",
    "            \n",
    "    \n",
    "        media_lag_mape_treino.append(np.mean(media_simulador_mape_treino))\n",
    "        media_lag_rmse_treino.append(np.mean(media_simulador_rmse_treino))\n",
    "        media_lag_r_treino.append(np.mean(media_simulador_r_treino))\n",
    "        \n",
    "        media_lag_mape_teste.append(np.mean(media_simulador_mape_teste))\n",
    "        media_lag_rmse_teste.append(np.mean(media_simulador_rmse_teste))\n",
    "        media_lag_r_teste.append(np.mean(media_simulador_r_teste))\n",
    "        \n",
    "                \n",
    "    #média\n",
    "    media_parametro_mape_treino.append(np.mean(media_lag_mape_treino))\n",
    "    media_parametro_rmse_treino.append(np.mean(media_lag_rmse_treino))\n",
    "    media_parametro_r_treino.append(np.mean(media_lag_r_treino))\n",
    "    \n",
    "    media_parametro_mape_teste.append(np.mean(media_lag_mape_teste))\n",
    "    media_parametro_rmse_teste.append(np.mean(media_lag_rmse_teste))\n",
    "    media_parametro_r_teste.append(np.mean(media_lag_r_teste))\n",
    "        \n",
    "    #desvio_padrão\n",
    "    \n",
    "    #std_parametro_mape_treino.append(np.std(media_lag_mape_treino))\n",
    "    std_parametro_rmse_treino.append(np.std(media_lag_rmse_treino))\n",
    "    #std_parametro_r_treino.append(np.std(media_lag_r_treino))\n",
    "    \n",
    "    #std_parametro_mape_teste.append(np.std(media_lag_mape_teste))\n",
    "    std_parametro_rmse_teste.append(np.std(media_lag_rmse_teste))\n",
    "    #std_parametro_r_teste.append(np.std(media_lag_r_teste))\n",
    "        \n",
    "    parametro.append(p)\n",
    "    tecnica.append('LSTM (Univar.)')\n",
    "    \n",
    "        \n",
    "dict = {'parametro': parametro,\n",
    "         'tecnica': tecnica,\n",
    "        'mape_treino':  media_parametro_mape_treino,  \n",
    "        'rmse_treino':  media_parametro_rmse_treino, 'std_rmse_treino':  std_parametro_rmse_treino,\n",
    "        'r_quad_treino':media_parametro_r_treino,    \n",
    "        'mape_teste':   media_parametro_mape_teste,   \n",
    "        'rmse_teste':   media_parametro_rmse_teste,  'std_rmse_teste':   std_parametro_rmse_teste,\n",
    "        'r_quad_teste': media_parametro_r_teste}\n",
    "   \n",
    "df_resultado_final = pd.DataFrame(dict)\n",
    "\n",
    "dframes = [df_resultado_medio_g,df_resultado_final]\n",
    "df_resultado_medio_g = pd.concat(dframes)\n",
    "\n",
    "df_resultado_medio_g.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
