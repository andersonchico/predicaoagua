{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_files = ''\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi06 = pd.read_csv(str_files + \"cetesb_concatenado06semoutliers.csv\",encoding='utf-8',sep=',',index_col=[0])\n",
    "\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi10 = pd.read_csv(str_files + \"cetesb_concatenado10semoutliers.csv\",encoding='utf-8',sep=',',index_col=[0])\n",
    "#Carrega os dados do arquivo .csv\n",
    "df_ugrhi10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Tamanho dos conjuntos originais ----\n",
      "ugrhi06: 503\n",
      "ugrhi10: 502\n",
      "---- Conjunto de dados y igualado ao tamanho de dados do conjunto X ----\n",
      "ugrhi06: 502\n",
      "ugrhi10: 502\n"
     ]
    }
   ],
   "source": [
    "print('---- Tamanho dos conjuntos originais ----')\n",
    "print('ugrhi06:',len(df_ugrhi06))\n",
    "print('ugrhi10:',len(df_ugrhi10))\n",
    "\n",
    "#Seleciona os dados equivalente ao tamanho da URGHI10\n",
    "df_ugrhi06 = df_ugrhi06.iloc[0:len(df_ugrhi10)]\n",
    "\n",
    "#Seleciona os valores da coluna ph da URGHI06, na qual será utilizado para a normalização dos dados quando apresentar o gráfico\n",
    "#train_previsao = ugrhi06['ph'].values\n",
    "#train_previsao = train_previsao.reshape(len(train_previsao),1)\n",
    "\n",
    "print('---- Conjunto de dados y igualado ao tamanho de dados do conjunto X ----')\n",
    "print('ugrhi06:',len(df_ugrhi06))\n",
    "print('ugrhi10:',len(df_ugrhi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBS.: O parâmetro temperatura não possui correlação suficiente para este tipo de experimento.\n",
    "def seleciona_colunas(trainingd,p,ugrhi):\n",
    "    \n",
    "    posicao_coluna = 0\n",
    "    frame_completo = pd.DataFrame()\n",
    "    \n",
    "    if (ugrhi == 6):\n",
    "            \n",
    "        if (p == 'ph'):\n",
    "            fcoliformes = trainingd.iloc[:,1:2].values\n",
    "            fdbo        = trainingd.iloc[:,2:3].values\n",
    "            fph         = trainingd.iloc[:,0:1].values\n",
    "            fsolido     = trainingd.iloc[:,5:6].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fcoliformes,fdbo,fsolido,fph)),columns =['coliformes','dbo','solido','ph']) \n",
    "            posicao_coluna = 3\n",
    "\n",
    "        elif (p == 'od'):\n",
    "            fod      = trainingd.iloc[:,4:5].values\n",
    "            fsolido  = trainingd.iloc[:,5:6].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fsolido,fod)),columns =['solido','od']) \n",
    "            posicao_coluna = 1\n",
    "\n",
    "        elif (p == 'coliformes'):\n",
    "            fph          = trainingd.iloc[:,0:1].values\n",
    "            fcoliformes  = trainingd.iloc[:,1:2].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fph,fcoliformes)),columns =['ph','coliformes']) \n",
    "            posicao_coluna = 1\n",
    "\n",
    "        elif (p == 'dbo'):\n",
    "            #ph, fosforo, solido tem correlação com o dbo\n",
    "            fph      = trainingd.iloc[:,0:1].values\n",
    "            fdbo     = trainingd.iloc[:,2:3].values\n",
    "            ffosforo = trainingd.iloc[:,3:4].values\n",
    "            fsolido  = trainingd.iloc[:,5:6].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fph,ffosforo,fsolido,fdbo)),columns =['ph','fosforo','solido','dbo']) \n",
    "            posicao_coluna = 3\n",
    "\n",
    "        elif (p == 'fosforo'):\n",
    "            # dbo e solido tem correlação com o fosforo\n",
    "            fdbo     = trainingd.iloc[:,2:3].values\n",
    "            ffosforo = trainingd.iloc[:,3:4].values\n",
    "            fsolido  = trainingd.iloc[:,5:6].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fdbo,fsolido,ffosforo)),columns =['dbo','solido','fosforo']) \n",
    "            posicao_coluna = 2\n",
    "\n",
    "        elif (p == 'solido'):\n",
    "            # ph, dbo, fosforo, od, solido e turbidez tem correlação com o solido\n",
    "            fph        = trainingd.iloc[:,0:1].values\n",
    "            fdbo       = trainingd.iloc[:,2:3].values\n",
    "            ffosforo   = trainingd.iloc[:,3:4].values\n",
    "            fod        = trainingd.iloc[:,4:5].values\n",
    "            fsolido    = trainingd.iloc[:,5:6].values\n",
    "            fturbidez  = trainingd.iloc[:,7:8].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fph,fdbo,ffosforo,fod,fturbidez,fsolido)),\n",
    "                                      columns =['ph','dbo','fosforo','od','turidez','solido']) \n",
    "            posicao_coluna = 5\n",
    "\n",
    "        elif (p == 'turbidez'):\n",
    "            # solido e turbidez tem correlação com o turbidez\n",
    "\n",
    "            fsolido    = trainingd.iloc[:,5:6].values\n",
    "            fturbidez  = trainingd.iloc[:,7:8].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fsolido,fturbidez)),columns =['solido','turidez']) \n",
    "            posicao_coluna = 1\n",
    "        \n",
    "    elif (ugrhi == 10):\n",
    "        \n",
    "        if (p == 'ph'):\n",
    "            fcoliformes = trainingd.iloc[:,2:3].values\n",
    "            fdbo        = trainingd.iloc[:,3:4].values\n",
    "            fph         = trainingd.iloc[:,1:2].values\n",
    "            fsolido     = trainingd.iloc[:,0:1].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fcoliformes,fdbo,fsolido,fph)),columns =['coliformes','dbo','solido','ph']) \n",
    "            posicao_coluna = 3\n",
    "\n",
    "        elif (p == 'od'):\n",
    "            fod      = trainingd.iloc[:,5:6].values\n",
    "            fsolido  = trainingd.iloc[:,0:1].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fsolido,fod)),columns =['solido','od']) \n",
    "            posicao_coluna = 1\n",
    "\n",
    "        elif (p == 'coliformes'):\n",
    "            fph          = trainingd.iloc[:,1:2].values\n",
    "            fcoliformes  = trainingd.iloc[:,2:3].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fph,fcoliformes)),columns =['ph','coliformes']) \n",
    "            posicao_coluna = 1\n",
    "\n",
    "        elif (p == 'dbo'):\n",
    "            #ph, fosforo, solido tem correlação com o dbo\n",
    "            fph      = trainingd.iloc[:,1:2].values\n",
    "            fdbo     = trainingd.iloc[:,3:4].values\n",
    "            ffosforo = trainingd.iloc[:,4:5].values\n",
    "            fsolido  = trainingd.iloc[:,0:1].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fph,ffosforo,fsolido,fdbo)),columns =['ph','fosforo','solido','dbo']) \n",
    "            posicao_coluna = 3\n",
    "\n",
    "        elif (p == 'fosforo'):\n",
    "            # dbo e solido tem correlação com o fosforo\n",
    "            fdbo     = trainingd.iloc[:,3:4].values\n",
    "            ffosforo = trainingd.iloc[:,4:5].values\n",
    "            fsolido  = trainingd.iloc[:,0:1].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fdbo,fsolido,ffosforo)),columns =['dbo','solido','fosforo']) \n",
    "            posicao_coluna = 2\n",
    "\n",
    "        elif (p == 'solido'):\n",
    "            # ph, dbo, fosforo, od, solido e turbidez tem correlação com o solido\n",
    "            fph        = trainingd.iloc[:,1:2].values\n",
    "            fdbo       = trainingd.iloc[:,3:4].values\n",
    "            ffosforo   = trainingd.iloc[:,4:5].values\n",
    "            fod        = trainingd.iloc[:,5:6].values\n",
    "            fsolido    = trainingd.iloc[:,0:1].values\n",
    "            fturbidez  = trainingd.iloc[:,7:8].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fph,fdbo,ffosforo,fod,fturbidez,fsolido)),\n",
    "                                      columns =['ph','dbo','fosforo','od','turidez','solido']) \n",
    "            posicao_coluna = 5\n",
    "\n",
    "        elif (p == 'turbidez'):\n",
    "            # solido e turbidez tem correlação com o turbidez\n",
    "\n",
    "            fsolido    = trainingd.iloc[:,0:1].values\n",
    "            fturbidez  = trainingd.iloc[:,7:8].values\n",
    "\n",
    "            frame_completo = pd.DataFrame(list(zip(fsolido,fturbidez)),columns =['solido','turidez']) \n",
    "            posicao_coluna = 1\n",
    "        \n",
    "    return frame_completo,posicao_coluna\n",
    "\n",
    "\n",
    "'''\n",
    "def seleciona_colunas(trainingd,ug):\n",
    "   \n",
    "    if (ug == 6):\n",
    "        fdbo     = trainingd.iloc[:,2:3].values\n",
    "        fph      = trainingd.iloc[:,0:1].values\n",
    "        fsolido  = trainingd.iloc[:,5:6].values\n",
    "   \n",
    "        frame_completo = pd.DataFrame(list(zip(fdbo,fsolido,fph)),columns =['dbo','solido','ph'])\n",
    "    else:\n",
    "        fdbo     = trainingd.iloc[:,3:4].values\n",
    "        fph      = trainingd.iloc[:,1:2].values\n",
    "        fsolido  = trainingd.iloc[:,0:1].values\n",
    "   \n",
    "        frame_completo = pd.DataFrame(list(zip(fdbo,fsolido,fph)),columns =['dbo','solido','ph'])\n",
    "       \n",
    "   \n",
    "    return frame_completo\n",
    "\n",
    "def seleciona_colunas_od(trainingd,ug):\n",
    "   \n",
    "    if (ug == 6):\n",
    "        fdbo     = trainingd.iloc[:,2:3].values\n",
    "        fod      = trainingd.iloc[:,4:5].values\n",
    "        fsolido  = trainingd.iloc[:,5:6].values\n",
    "   \n",
    "        frame_completo = pd.DataFrame(list(zip(fdbo,fsolido,fod)),columns =['dbo','solido','od'])\n",
    "    else:\n",
    "        fdbo     = trainingd.iloc[:,3:4].values\n",
    "        fod      = trainingd.iloc[:,5:6].values\n",
    "        fsolido  = trainingd.iloc[:,0:1].values\n",
    "   \n",
    "        frame_completo = pd.DataFrame(list(zip(fdbo,fsolido,fod)),columns =['dbo','solido','od'])\n",
    "       \n",
    "   \n",
    "    return frame_completo\n",
    "    \n",
    "'''\n",
    "\n",
    "def pegar_dados_coluna_predita_train_test(trainingd,percent,index_coluna):\n",
    "    data = trainingd.iloc[:,:].values\n",
    "    train = trainingd.iloc[0:int(len(data)*percent),:].values  \n",
    "    train_previsao = trainingd.iloc[0:int(len(data)*percent),index_coluna:index_coluna+1].values\n",
    "    test = trainingd.iloc[len(train):,index_coluna:index_coluna+1].values\n",
    "    \n",
    "    return train,train_previsao, test\n",
    "\n",
    "#Normalização dos dados: Normaliza os dados dentro um intervalo (0 a 1).\n",
    "def normalizacao(train,test):\n",
    "    sc = MinMaxScaler()\n",
    "    testd = test\n",
    "    train = sc.fit_transform(train)\n",
    "    test = sc.fit_transform(test)    \n",
    "    return train,test,testd\n",
    "\n",
    "#Prepara o conjunto de dados em X e y, considerando a janela de visualização (lags).\n",
    "#cy = coluna que será predita\n",
    "def prepara_dados(dados,lags,cy):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(lags, len(dados)):\n",
    "        X.append(dados[i-lags:i,:])\n",
    "        y.append(dados[i, cy])\n",
    "       \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#Calcula o MAPE\n",
    "#Define função para calcular o MAPE\n",
    "#def mape(y_pred,y_true):\n",
    " #   return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mape(y_pred,y_true):\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    '''  \n",
    "    mape_sum = 0\n",
    "    for real,prediction in zip(y_true,y_pred):\n",
    "        mape_sum += (abs((real - prediction))/real)\n",
    "        \n",
    "        print(real)\n",
    "        mape = mape_sum/len(real)\n",
    "    '''\n",
    "    return mape\n",
    "\n",
    "def rmse(y_pred,y_true):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def r2(y_pred,y_true):\n",
    "    rscore = r2_score(y_true,y_pred)\n",
    "    return rscore\n",
    "\n",
    "def rquadrado(y_pred,y_true):\n",
    "    #Soma Total dos Quadrados (STQ): mostra a variação de y em torno da própria média. \n",
    "    #É o somatório das diferenças entre o valor alvo real e sua média elevado ao quadrado.\n",
    "    y_traco = np.mean(y_true)\n",
    "    \n",
    "    print('media y_true:', y_traco)\n",
    "        \n",
    "    stq = 0\n",
    "    \n",
    "    for s in y_true:\n",
    "        a = s - y_traco\n",
    "        st = a * a\n",
    "        stq = stq + st\n",
    "    \n",
    "    print('Soma Total dos Quadrados (STQ):', stq[0])\n",
    "    \n",
    "    #Soma dos Quadrados dos Resíduos (SQU): variação de Y que não é explicada pelo modelo elaborado. \n",
    "    #É o somatório das diferenças entre o valor predito e o valor real elevados ao quadrado.\n",
    "    squ = 0\n",
    "    \n",
    "    y_traco = np.mean(y_pred)\n",
    "    print('media y_pred:', y_traco)\n",
    "    \n",
    "    for n in range(len(y_true)):\n",
    "        a = y_true[n] - y_pred[n]\n",
    "        st = a * a\n",
    "        squ = squ + st\n",
    "        \n",
    "    print('Soma dos Quadrados dos Resíduos (SQU):',squ[0])\n",
    "    print('\\n')\n",
    "    print('Fórmula do R²')\n",
    "    print('\\n')\n",
    "    print('sqr = stq - squ')\n",
    "    sqr = stq[0] - squ[0]\n",
    "    print('R² = sqr/stq')\n",
    "    sqr = sqr/stq[0]\n",
    "    print('\\n')\n",
    "    return sqr\n",
    "\n",
    "def correlacao_determinacao(dtframe,tipo):\n",
    "    \n",
    "    if (tipo == 0): #Treino\n",
    "        resultado = dtframe.corr().previsao_treino.values[1] ** 2 \n",
    "    else: #teste\n",
    "        resultado = dtframe.corr().previsao_teste.values[1] ** 2\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "def ajusta_array(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def ajusta_lista(array):\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        lista.append(array[i][0])\n",
    "        \n",
    "    #print('ajusta array:',lista)\n",
    "        \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      dbo                solido                   ph\n",
      "0    [19.932203389830512]  [291.30508474576266]  [6.415254237288135]\n",
      "1    [19.122792353533008]   [290.8506307561334]  [6.404951629130872]\n",
      "2    [18.226658706203636]   [290.3474852676153]  [6.393545170099616]\n",
      "3    [17.359432595884886]  [289.86057027872675]  [6.382506661359692]\n",
      "4    [16.463298948555508]  [289.35742479020865]  [6.371100202328434]\n",
      "..                    ...                   ...                  ...\n",
      "497  [55.922077922077925]   [352.8438644688645]               [7.56]\n",
      "498   [41.02597402597402]  [344.76739926739924]               [7.34]\n",
      "499  [26.129870129870127]  [336.69093406593413]               [7.37]\n",
      "500  [11.714285714285715]             [328.875]  [6.827000000000001]\n",
      "501  [11.714285714285715]             [328.875]               [6.92]\n",
      "\n",
      "[502 rows x 3 columns]\n",
      "                      dbo                solido                    ph\n",
      "0     [4.916666666666667]  [189.79166666666663]   [7.094057396342201]\n",
      "1     [4.788812785388128]  [192.11860730593602]   [7.105960703508023]\n",
      "2     [4.647260273972604]   [194.6948630136986]   [7.105960703508023]\n",
      "3      [4.51027397260274]  [197.18801369863013]   [7.120679481845853]\n",
      "4     [4.368721461187215]  [199.76426940639266]   [7.120679481845853]\n",
      "..                    ...                   ...                   ...\n",
      "497   [7.481632653061224]   [361.5061224489796]   [7.136286635823778]\n",
      "498   [8.620408163265306]   [345.6265306122449]   [7.136286635823778]\n",
      "499   [9.759183673469387]  [329.74693877551016]  [7.2068979591836735]\n",
      "500  [10.861224489795921]   [314.3795918367347]  [7.1346530612244905]\n",
      "501                [12.0]               [298.5]  [7.0600000000000005]\n",
      "\n",
      "[502 rows x 3 columns]\n",
      "Epoch 00007: early stopping\n",
      "Teste - Gráficos com lag 1\n",
      "Treinamento - Gráficos com lag 1\n",
      "Epoch 00010: early stopping\n",
      "Teste - Gráficos com lag 2\n",
      "Treinamento - Gráficos com lag 2\n",
      "Epoch 00011: early stopping\n",
      "Teste - Gráficos com lag 3\n",
      "Treinamento - Gráficos com lag 3\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 4\n",
      "Treinamento - Gráficos com lag 4\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 5\n",
      "Treinamento - Gráficos com lag 5\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 6\n",
      "Treinamento - Gráficos com lag 6\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 7\n",
      "Treinamento - Gráficos com lag 7\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 8\n",
      "Treinamento - Gráficos com lag 8\n",
      "Epoch 00006: early stopping\n",
      "Teste - Gráficos com lag 9\n",
      "Treinamento - Gráficos com lag 9\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 10\n",
      "Treinamento - Gráficos com lag 10\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 11\n",
      "Treinamento - Gráficos com lag 11\n",
      "Epoch 00006: early stopping\n",
      "Teste - Gráficos com lag 12\n",
      "Treinamento - Gráficos com lag 12\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 13\n",
      "Treinamento - Gráficos com lag 13\n",
      "Epoch 00005: early stopping\n",
      "Teste - Gráficos com lag 14\n",
      "Treinamento - Gráficos com lag 14\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 15\n",
      "Treinamento - Gráficos com lag 15\n",
      "Epoch 00006: early stopping\n",
      "Teste - Gráficos com lag 16\n",
      "Treinamento - Gráficos com lag 16\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 17\n",
      "Treinamento - Gráficos com lag 17\n",
      "Epoch 00011: early stopping\n",
      "Teste - Gráficos com lag 18\n",
      "Treinamento - Gráficos com lag 18\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 19\n",
      "Treinamento - Gráficos com lag 19\n",
      "Epoch 00004: early stopping\n",
      "Teste - Gráficos com lag 20\n",
      "Treinamento - Gráficos com lag 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags_treino</th>\n",
       "      <th>mape_treino</th>\n",
       "      <th>rmse_treino</th>\n",
       "      <th>r_quad_treino</th>\n",
       "      <th>lags_teste</th>\n",
       "      <th>mape_teste</th>\n",
       "      <th>rmse_teste</th>\n",
       "      <th>r_quad_teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.344500</td>\n",
       "      <td>0.382580</td>\n",
       "      <td>0.104740</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.344835</td>\n",
       "      <td>0.383650</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.91608</td>\n",
       "      <td>0.261756</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>5.91608</td>\n",
       "      <td>0.309333</td>\n",
       "      <td>0.021802</td>\n",
       "      <td>0.004483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.047600</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.907700</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.75000</td>\n",
       "      <td>5.103875</td>\n",
       "      <td>0.366750</td>\n",
       "      <td>0.095250</td>\n",
       "      <td>5.75000</td>\n",
       "      <td>5.114925</td>\n",
       "      <td>0.367450</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.260150</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.105850</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>5.250350</td>\n",
       "      <td>0.377250</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.25000</td>\n",
       "      <td>5.499675</td>\n",
       "      <td>0.393425</td>\n",
       "      <td>0.121725</td>\n",
       "      <td>15.25000</td>\n",
       "      <td>5.535475</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>0.005775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>5.876500</td>\n",
       "      <td>0.420100</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>5.938900</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lags_treino  mape_treino  rmse_treino  r_quad_treino  lags_teste  \\\n",
       "count     20.00000    20.000000    20.000000      20.000000    20.00000   \n",
       "mean      10.50000     5.344500     0.382580       0.104740    10.50000   \n",
       "std        5.91608     0.261756     0.018399       0.023815     5.91608   \n",
       "min        1.00000     5.047600     0.361600       0.027500     1.00000   \n",
       "25%        5.75000     5.103875     0.366750       0.095250     5.75000   \n",
       "50%       10.50000     5.260150     0.376600       0.105850    10.50000   \n",
       "75%       15.25000     5.499675     0.393425       0.121725    15.25000   \n",
       "max       20.00000     5.876500     0.420100       0.133900    20.00000   \n",
       "\n",
       "       mape_teste  rmse_teste  r_quad_teste  \n",
       "count   20.000000   20.000000     20.000000  \n",
       "mean     5.344835    0.383650      0.004075  \n",
       "std      0.309333    0.021802      0.004483  \n",
       "min      4.907700    0.353900      0.000000  \n",
       "25%      5.114925    0.367450      0.000975  \n",
       "50%      5.250350    0.377250      0.002100  \n",
       "75%      5.535475    0.396900      0.005775  \n",
       "max      5.938900    0.425600      0.015800  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultado_medio_g = pd.DataFrame()\n",
    "\n",
    "index_coluna = 0\n",
    "\n",
    "parametro = []\n",
    "tecnica   = []\n",
    "\n",
    "#média\n",
    "media_parametro_mape_treino = []\n",
    "media_parametro_rmse_treino = []\n",
    "media_parametro_r_treino    = []\n",
    "    \n",
    "media_parametro_mape_teste  = []\n",
    "media_parametro_rmse_teste  = []\n",
    "media_parametro_r_teste     = []\n",
    "    \n",
    "#desvio_padrão\n",
    "    \n",
    "std_parametro_mape_treino = []\n",
    "std_parametro_rmse_treino = []\n",
    "std_parametro_r_treino    = []\n",
    "    \n",
    "std_parametro_mape_teste  = []\n",
    "std_parametro_rmse_teste  = []\n",
    "std_parametro_r_teste     = []\n",
    "\n",
    "for p in ('ph','coliformes', 'dbo','fosforo','od','solido','turbidez'):\n",
    "    \n",
    "    print('Agora é a vez do parâmetro:', p)\n",
    "   \n",
    "    ugrhi06,posicao_col06   = seleciona_colunas(df_ugrhi06,p,6)\n",
    "    ugrhi10,posicao_col10   = seleciona_colunas(df_ugrhi10,p,10)\n",
    "    #index_coluna10 = pega_index_coluna_ugrhi10(p)\n",
    "          \n",
    "    #index_coluna = index_coluna + 1\n",
    "\n",
    "    df_resultados_treino = pd.DataFrame()\n",
    "    df_resultados_teste  = pd.DataFrame()\n",
    "    df_resultados        = pd.DataFrame()\n",
    "    \n",
    "    media_lag_mape_treino = []\n",
    "    media_lag_rmse_treino = []\n",
    "    media_lag_r_treino    = []\n",
    "        \n",
    "    media_lag_mape_teste = []\n",
    "    media_lag_rmse_teste = []\n",
    "    media_lag_r_teste    = []\n",
    "    \n",
    "    for l in range(1, 16):\n",
    "    \n",
    "        lags = l\n",
    "\n",
    "        #seleciona os dados\n",
    "\n",
    "        train06,train_previsao06, test06 = pegar_dados_coluna_predita_train_test(ugrhi06,0.70,posicao_col06) \n",
    "        train10,train_previsao10, test10 = pegar_dados_coluna_predita_train_test(ugrhi10,0.70,posicao_col10) \n",
    "\n",
    "        #normalização dos dados\n",
    "        train06,test06,testd06 = normalizacao(train06,test06)\n",
    "        train10,test10,testd10 = normalizacao(train10,test10)\n",
    "\n",
    "        normalizador_previsao = MinMaxScaler()\n",
    "        sc = MinMaxScaler()\n",
    "        normalizador_previsao.fit_transform(train_previsao06)\n",
    "\n",
    "        #Prepara os dados de treinamento -ugrhi06\n",
    "        #Vai predizer o valor da coluna 4 (valor ph)\n",
    "        train_X06, train_y06 = prepara_dados(train06, lags,posicao_col06)\n",
    "\n",
    "        #Prepara os dados de teste\n",
    "        entradas06 = ugrhi06[len(ugrhi06) - len(test06) - lags:].values\n",
    "        entradas06 = sc.fit_transform(entradas06)   \n",
    "\n",
    "        test_X06 = []\n",
    "        for i in range(lags, lags+len(test06)):\n",
    "            test_X06.append(entradas06[i-lags:i, 0:posicao_col06+1])\n",
    "        test_X06 = np.array(test_X06)\n",
    "\n",
    "        #Prepara os dados de treinamento -ugrhi10\n",
    "        #Aqui vamos pegar test_X10.\n",
    "        train_X10, train_y10 = prepara_dados(train10, lags,posicao_col10)\n",
    "\n",
    "        #Prepara os dados de teste\n",
    "        entradas10 = ugrhi10[len(ugrhi10) - len(test10) - lags:].values\n",
    "        entradas10 = sc.fit_transform(entradas10)   \n",
    "\n",
    "        test_X10 = []\n",
    "        for i in range(lags, lags+len(test10)):\n",
    "            test_X10.append(entradas10[i-lags:i, 0:posicao_col10+1])\n",
    "        test_X10 = np.array(test_X10)\n",
    "        \n",
    "        media_simulador_mape_treino = []\n",
    "        media_simulador_rmse_treino = []\n",
    "        media_simulador_r_treino    = []\n",
    "            \n",
    "        media_simulador_mape_teste  = []\n",
    "        media_simulador_rmse_teste  = []\n",
    "        media_simulador_r_teste     = []\n",
    "        \n",
    "        for r in range(0,6)\n",
    "    \n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units = 10, input_shape = (train_X06.shape[1], 3)))\n",
    "            model.add(Dense(10, activation = 'relu'))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(1, activation = 'sigmoid'))\n",
    "            model.compile(loss = 'mean_absolute_error', optimizer = 'adam',\n",
    "                          metrics = ['mean_absolute_error'])\n",
    "\n",
    "            es = EarlyStopping(monitor='val_loss', patience = 3, verbose=0)\n",
    "\n",
    "\n",
    "            #Treina o modelo\n",
    "            history = model.fit(train_X06, train_y06, validation_data=(test_X10, test10), batch_size = 32, epochs = 2000, \n",
    "                                callbacks=[es], verbose=0)\n",
    "\n",
    "            #Treina o modelo\n",
    "            #model.fit(train_X06, train_y06, batch_size = 32, epochs = 100)\n",
    "\n",
    "            #Dados de teste\n",
    "            previsoes = model.predict(test_X10)\n",
    "            #previsoes = previsoes.reshape(-1, 1)\n",
    "            previsoes = normalizador_previsao.inverse_transform(previsoes)\n",
    "\n",
    "            #print('Teste - Gráficos com lag', l)\n",
    "            '''\n",
    "            #Plotagem do gráfico\n",
    "            plt.plot(testd10,color='red',label = 'Observado')\n",
    "            plt.plot(previsoes,color='blue',label = 'Previsoes')\n",
    "            plt.xlabel('Tempo')\n",
    "            plt.ylabel('Valor pH')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            #Dados de treino\n",
    "            previsoes_treino = model.predict(train_X10)\n",
    "            previsoes_treino = previsoes_treino.reshape(-1, 1)\n",
    "            previsoes_treino = normalizador_previsao.inverse_transform(previsoes_treino)\n",
    "\n",
    "            treino = train_previsao10[lags: len(previsoes_treino) + lags, :]\n",
    "            observado_test = testd10\n",
    "\n",
    "            observado_treino = train_previsao10  \n",
    "\n",
    "            #print('Treinamento - Gráficos com lag', l)\n",
    "            '''\n",
    "            #Plotagem do gráfico\n",
    "            plt.plot(train_previsao10,color='red',label = 'Observado')\n",
    "            plt.plot(previsoes_treino,color='blue',label = 'Previsoes')\n",
    "            plt.xlabel('Tempo')\n",
    "            plt.ylabel('Valor pH')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            treino         = ajusta_array(treino)\n",
    "            observado_test = ajusta_array(observado_test)\n",
    "\n",
    "            #Calculo do erro da previsão MAPE, RMSE e R²\n",
    "\n",
    "            observado_treino_d = observado_treino\n",
    "            previsoes_treino_d = previsoes_treino\n",
    "            previsoes_d        = previsoes\n",
    "\n",
    "            mape_treino_d        = round(mape(previsoes_treino,treino),4)\n",
    "            rmse_treino_d        = round(rmse(previsoes_treino,treino),4)\n",
    "            #r_treino_d           = round(r2(previsoes_treino,treino),4)\n",
    "\n",
    "            mape_teste_d        = round(mape(previsoes,observado_test),4)\n",
    "            rmse_teste_d        = round(rmse(previsoes,observado_test),4)\n",
    "            #r_teste_d           = round(r2(previsoes,observado_test),4) \n",
    "\n",
    "            df_corr_determinacao_treino = pd.DataFrame()\n",
    "            df_corr_determinacao_teste  = pd.DataFrame()\n",
    "\n",
    "            #Calcula o coeficiente de determinação\n",
    "            dict = {'previsao_treino': ajusta_lista(previsoes_treino), 'treino': ajusta_array(treino)} \n",
    "\n",
    "            df_treino = pd.DataFrame(dict)\n",
    "            dframes_treino = [df_corr_determinacao_treino,df_treino]\n",
    "            df_corr_determinacao_treino = pd.concat(dframes_treino)\n",
    "\n",
    "            dict = {'previsao_teste': ajusta_lista(previsoes), 'teste': ajusta_array(observado_test)} \n",
    "\n",
    "            df_teste = pd.DataFrame(dict)\n",
    "            dframes_teste = [df_corr_determinacao_teste,df_teste]\n",
    "            df_corr_determinacao_teste = pd.concat(dframes_teste)\n",
    "\n",
    "            r_treino_d = []\n",
    "            r_teste_d  = []\n",
    "\n",
    "            r_treino_d.append(round(correlacao_determinacao(df_corr_determinacao_treino,0),4))\n",
    "            r_teste_d.append(round(correlacao_determinacao(df_corr_determinacao_teste,1),4))\n",
    "\n",
    "            media_simulador_mape_treino.append(np.mean(mape_treino_d))\n",
    "            media_simulador_rmse_treino.append(np.mean(rmse_treino_d))\n",
    "            media_simulador_r_treino.append(np.mean(r_treino_d))\n",
    "            \n",
    "            media_simulador_mape_teste.append(np.mean(mape_teste_d))\n",
    "            media_simulador_rmse_teste.append(np.mean(rmse_teste_d))\n",
    "            media_simulador_r_teste.append(np.mean(r_teste_d))\n",
    "            \n",
    "            \n",
    "    \n",
    "        media_lag_mape_treino.append(np.mean(media_simulador_mape_treino))\n",
    "        media_lag_rmse_treino.append(np.mean(media_simulador_rmse_treino))\n",
    "        media_lag_r_treino.append(np.mean(media_simulador_r_treino))\n",
    "        \n",
    "        media_lag_mape_teste.append(np.mean(media_simulador_mape_teste))\n",
    "        media_lag_rmse_teste.append(np.mean(media_simulador_rmse_teste))\n",
    "        media_lag_r_teste.append(np.mean(media_simulador_r_teste))\n",
    "        \n",
    "                \n",
    "    #média\n",
    "    media_parametro_mape_treino.append(np.mean(media_lag_mape_treino))\n",
    "    media_parametro_rmse_treino.append(np.mean(media_lag_rmse_treino))\n",
    "    media_parametro_r_treino.append(np.mean(media_lag_r_treino))\n",
    "    \n",
    "    media_parametro_mape_teste.append(np.mean(media_lag_mape_teste))\n",
    "    media_parametro_rmse_teste.append(np.mean(media_lag_rmse_teste))\n",
    "    media_parametro_r_teste.append(np.mean(media_lag_r_teste))\n",
    "        \n",
    "    #desvio_padrão\n",
    "    \n",
    "    #std_parametro_mape_treino.append(np.std(media_lag_mape_treino))\n",
    "    std_parametro_rmse_treino.append(np.std(media_lag_rmse_treino))\n",
    "    #std_parametro_r_treino.append(np.std(media_lag_r_treino))\n",
    "    \n",
    "    #std_parametro_mape_teste.append(np.std(media_lag_mape_teste))\n",
    "    std_parametro_rmse_teste.append(np.std(media_lag_rmse_teste))\n",
    "    #std_parametro_r_teste.append(np.std(media_lag_r_teste))\n",
    "        \n",
    "    parametro.append(p)\n",
    "    tecnica.append('MLP (Var. selec.)')\n",
    "    \n",
    "dict = {'parametro': parametro,\n",
    "        'mape_treino':  media_parametro_mape_treino,  \n",
    "        'rmse_treino':  media_parametro_rmse_treino, 'std_rmse_treino':  std_parametro_rmse_treino,\n",
    "        'r_quad_treino':media_parametro_r_treino,    \n",
    "        'mape_teste':   media_parametro_mape_teste,   \n",
    "        'rmse_teste':   media_parametro_rmse_teste,  'std_rmse_teste':   std_parametro_rmse_teste,\n",
    "        'r_quad_teste': media_parametro_r_teste}\n",
    "   \n",
    "df_resultado_final = pd.DataFrame(dict)\n",
    "\n",
    "dframes = [df_resultado_medio_g,df_resultado_final]\n",
    "df_resultado_medio_g = pd.concat(dframes)\n",
    "\n",
    "df_resultado_medio_g.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado_medio_g.round(2).to_csv (r'C:\\Users\\Anderson\\predicaoagua\\src\\src_dissertação\\resultados\\lstm_espaco_temporal_var_selec.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
